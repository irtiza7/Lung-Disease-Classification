{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:15.749048Z",
     "iopub.status.busy": "2022-11-24T06:53:15.748567Z",
     "iopub.status.idle": "2022-11-24T06:53:27.484049Z",
     "shell.execute_reply": "2022-11-24T06:53:27.483190Z",
     "shell.execute_reply.started": "2022-11-24T06:53:15.748957Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:27.486457Z",
     "iopub.status.busy": "2022-11-24T06:53:27.485775Z",
     "iopub.status.idle": "2022-11-24T06:53:28.447285Z",
     "shell.execute_reply": "2022-11-24T06:53:28.446226Z",
     "shell.execute_reply.started": "2022-11-24T06:53:27.486415Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset_information/Data_Entry_2017.csv')\n",
    "\n",
    "diseases = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n",
    "#Number diseases\n",
    "for disease in diseases :\n",
    "    df[disease] = df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:28.448882Z",
     "iopub.status.busy": "2022-11-24T06:53:28.448513Z",
     "iopub.status.idle": "2022-11-24T06:53:32.696559Z",
     "shell.execute_reply": "2022-11-24T06:53:32.695633Z",
     "shell.execute_reply.started": "2022-11-24T06:53:28.448843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images found: 112120\n"
     ]
    }
   ],
   "source": [
    "all_image_paths = {os.path.basename(x): x for x in glob(os.path.join('.' ,'images', '*.png'))}\n",
    "print('Images found:', len(all_image_paths))\n",
    "df['Path'] = df['Image Index'].map(all_image_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.699639Z",
     "iopub.status.busy": "2022-11-24T06:53:32.698542Z",
     "iopub.status.idle": "2022-11-24T06:53:32.759079Z",
     "shell.execute_reply": "2022-11-24T06:53:32.758208Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.699595Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = df[diseases].to_numpy()\n",
    "files_list = df['Path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.760679Z",
     "iopub.status.busy": "2022-11-24T06:53:32.760288Z",
     "iopub.status.idle": "2022-11-24T06:53:32.781774Z",
     "shell.execute_reply": "2022-11-24T06:53:32.780601Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.760640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labelB = (df[diseases].sum(axis=1)>0).tolist()\n",
    "labelB = np.array(labelB, dtype=int)\n",
    "print(labelB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.783446Z",
     "iopub.status.busy": "2022-11-24T06:53:32.783129Z",
     "iopub.status.idle": "2022-11-24T06:53:32.841697Z",
     "shell.execute_reply": "2022-11-24T06:53:32.840801Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.783409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 75120  Testing: 37000\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df,test_size = 0.33,random_state = 2018)\n",
    "print(f'Training : {train_df.shape[0]}  Testing: {test_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.843639Z",
     "iopub.status.busy": "2022-11-24T06:53:32.843239Z",
     "iopub.status.idle": "2022-11-24T06:53:32.870112Z",
     "shell.execute_reply": "2022-11-24T06:53:32.869042Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.843599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9733\n"
     ]
    }
   ],
   "source": [
    "patient_train = set(train_df[\"Patient ID\"].values)\n",
    "patient_test  = set(test_df[\"Patient ID\"].values)\n",
    "\n",
    "leakage_patient = patient_train.intersection(patient_test)\n",
    "print(len(leakage_patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.872407Z",
     "iopub.status.busy": "2022-11-24T06:53:32.871254Z",
     "iopub.status.idle": "2022-11-24T06:53:32.901038Z",
     "shell.execute_reply": "2022-11-24T06:53:32.900063Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.872342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.2656283280085197\n",
      "75120\n",
      "19954\n",
      "\n",
      "Test\n",
      "0.18975675675675677\n",
      "37000\n",
      "7021\n"
     ]
    }
   ],
   "source": [
    "train_without_leakage = train_df[~train_df[\"Patient ID\"].isin(leakage_patient)]\n",
    "\n",
    "print(\"Train\")\n",
    "print(len(train_without_leakage) / len(train_df))\n",
    "print(len(train_df))\n",
    "print(len(train_without_leakage))\n",
    "\n",
    "print()\n",
    "print(\"Test\")\n",
    "test_without_leakage = test_df[~test_df[\"Patient ID\"].isin(leakage_patient)]\n",
    "print(len(test_without_leakage) / len(test_df))\n",
    "print(len(test_df))\n",
    "print(len(test_without_leakage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.903058Z",
     "iopub.status.busy": "2022-11-24T06:53:32.902623Z",
     "iopub.status.idle": "2022-11-24T06:53:32.908678Z",
     "shell.execute_reply": "2022-11-24T06:53:32.907788Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.903021Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = test_without_leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.913291Z",
     "iopub.status.busy": "2022-11-24T06:53:32.912616Z",
     "iopub.status.idle": "2022-11-24T06:53:32.953867Z",
     "shell.execute_reply": "2022-11-24T06:53:32.953011Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.913252Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.955851Z",
     "iopub.status.busy": "2022-11-24T06:53:32.955042Z",
     "iopub.status.idle": "2022-11-24T06:53:32.962672Z",
     "shell.execute_reply": "2022-11-24T06:53:32.961655Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.955810Z"
    }
   },
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path, shape):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=shape)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)/255\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths, shape):\n",
    "    list_of_tensors = [path_to_tensor(img_path, shape) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T06:53:32.965856Z",
     "iopub.status.busy": "2022-11-24T06:53:32.965182Z",
     "iopub.status.idle": "2022-11-24T07:28:31.595521Z",
     "shell.execute_reply": "2022-11-24T07:28:31.594594Z",
     "shell.execute_reply.started": "2022-11-24T06:53:32.965818Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▊                                                    | 23597/60096 [06:27<10:54, 55.79it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpaths_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m valid_tensors \u001b[38;5;241m=\u001b[39m paths_to_tensor(valid_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(), shape \u001b[38;5;241m=\u001b[39m img_shape)\n\u001b[0;32m      4\u001b[0m test_tensors \u001b[38;5;241m=\u001b[39m paths_to_tensor(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(), shape \u001b[38;5;241m=\u001b[39m img_shape)\n",
      "Cell \u001b[1;32mIn [11], line 10\u001b[0m, in \u001b[0;36mpaths_to_tensor\u001b[1;34m(img_paths, shape)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpaths_to_tensor\u001b[39m(img_paths, shape):\n\u001b[1;32m---> 10\u001b[0m     list_of_tensors \u001b[38;5;241m=\u001b[39m [path_to_tensor(img_path, shape) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(img_paths)]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(list_of_tensors)\n",
      "Cell \u001b[1;32mIn [11], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpaths_to_tensor\u001b[39m(img_paths, shape):\n\u001b[1;32m---> 10\u001b[0m     list_of_tensors \u001b[38;5;241m=\u001b[39m [\u001b[43mpath_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(img_paths)]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(list_of_tensors)\n",
      "Cell \u001b[1;32mIn [11], line 3\u001b[0m, in \u001b[0;36mpath_to_tensor\u001b[1;34m(img_path, shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpath_to_tensor\u001b[39m(img_path, shape):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# loads RGB image as PIL.Image.Image type\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:313\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.utils.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    278\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m              interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    281\u001b[0m   \u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m  Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:125\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_mode must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\PIL\\Image.py:901\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    858\u001b[0m ):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\PIL\\ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         )\n\u001b[0;32m    256\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 257\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_shape = (64, 64)\n",
    "train_tensors = paths_to_tensor(train_df['Path'].to_list(), shape = img_shape)\n",
    "valid_tensors = paths_to_tensor(valid_df['Path'].to_list(), shape = img_shape)\n",
    "test_tensors = paths_to_tensor(test_df['Path'].to_list(), shape = img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.597685Z",
     "iopub.status.busy": "2022-11-24T07:28:31.597267Z",
     "iopub.status.idle": "2022-11-24T07:28:31.629025Z",
     "shell.execute_reply": "2022-11-24T07:28:31.628108Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.597646Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = (train_df[diseases].sum(axis=1)>0).tolist()\n",
    "train_labels = np.array(train_labels, dtype=int)\n",
    "train_labels = train_labels[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.631143Z",
     "iopub.status.busy": "2022-11-24T07:28:31.630661Z",
     "iopub.status.idle": "2022-11-24T07:28:31.644583Z",
     "shell.execute_reply": "2022-11-24T07:28:31.643616Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.631103Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.646624Z",
     "iopub.status.busy": "2022-11-24T07:28:31.646209Z",
     "iopub.status.idle": "2022-11-24T07:28:31.657293Z",
     "shell.execute_reply": "2022-11-24T07:28:31.656306Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.646575Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_labels = (valid_df[diseases].sum(axis=1)>0).tolist()\n",
    "valid_labels = np.array(valid_labels, dtype=int)\n",
    "valid_labels =valid_labels[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.659190Z",
     "iopub.status.busy": "2022-11-24T07:28:31.658822Z",
     "iopub.status.idle": "2022-11-24T07:28:31.670393Z",
     "shell.execute_reply": "2022-11-24T07:28:31.669706Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.659154Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels = (test_df[diseases].sum(axis=1)>0).tolist()\n",
    "test_labels = np.array(test_labels, dtype=int)\n",
    "test_labels =test_labels[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.671766Z",
     "iopub.status.busy": "2022-11-24T07:28:31.671413Z",
     "iopub.status.idle": "2022-11-24T07:28:31.682571Z",
     "shell.execute_reply": "2022-11-24T07:28:31.681856Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.671732Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.684670Z",
     "iopub.status.busy": "2022-11-24T07:28:31.684328Z",
     "iopub.status.idle": "2022-11-24T07:28:31.693743Z",
     "shell.execute_reply": "2022-11-24T07:28:31.693055Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.684634Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.696926Z",
     "iopub.status.busy": "2022-11-24T07:28:31.696660Z",
     "iopub.status.idle": "2022-11-24T07:28:31.715848Z",
     "shell.execute_reply": "2022-11-24T07:28:31.714949Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.696902Z"
    }
   },
   "outputs": [],
   "source": [
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:31.717616Z",
     "iopub.status.busy": "2022-11-24T07:28:31.717218Z",
     "iopub.status.idle": "2022-11-24T07:28:32.243156Z",
     "shell.execute_reply": "2022-11-24T07:28:32.242320Z",
     "shell.execute_reply.started": "2022-11-24T07:28:31.717582Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:32.245753Z",
     "iopub.status.busy": "2022-11-24T07:28:32.244309Z",
     "iopub.status.idle": "2022-11-24T07:28:38.101662Z",
     "shell.execute_reply": "2022-11-24T07:28:38.100845Z",
     "shell.execute_reply.started": "2022-11-24T07:28:32.245718Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=train_tensors.shape[1:])\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "\n",
    "add_model.add(Dense(50, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "\n",
    "# model.summary()\n",
    "# add_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:28:38.103494Z",
     "iopub.status.busy": "2022-11-24T07:28:38.103105Z",
     "iopub.status.idle": "2022-11-24T07:28:38.118913Z",
     "shell.execute_reply": "2022-11-24T07:28:38.117935Z",
     "shell.execute_reply.started": "2022-11-24T07:28:38.103456Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizers.SGD(\n",
    "        learning_rate=1e-4, \n",
    "        decay=1e-6, \n",
    "        momentum=0.9, \n",
    "        nesterov=True), \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        precision_threshold(threshold = 0.5), \n",
    "        recall_threshold(threshold = 0.5), \n",
    "        fbeta_score_threshold(beta=0.5, threshold = 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:53:35.543802Z",
     "iopub.status.busy": "2022-11-24T07:53:35.543355Z",
     "iopub.status.idle": "2022-11-24T08:11:46.516684Z",
     "shell.execute_reply": "2022-11-24T08:11:46.515560Z",
     "shell.execute_reply.started": "2022-11-24T07:53:35.543767Z"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "Epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "log = CSVLogger('saved_models/log_pretrained_CNN.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/pretrainedVGG.best.from_scratch.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False \n",
    ")\n",
    "\n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(train_tensors,train_labels, batch_size = batch_size),\n",
    "    steps_per_epoch = len(train_tensors) // batch_size,\n",
    "    validation_data = (valid_tensors, valid_labels),\n",
    "    validation_steps = len(valid_tensors) // batch_size,\n",
    "    epochs = Epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:11:53.737919Z",
     "iopub.status.busy": "2022-11-24T08:11:53.737526Z",
     "iopub.status.idle": "2022-11-24T08:11:59.257351Z",
     "shell.execute_reply": "2022-11-24T08:11:59.256516Z",
     "shell.execute_reply.started": "2022-11-24T08:11:53.737887Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "prediction = model.predict(test_tensors)\n",
    "\n",
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels), K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels), K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(binary_accuracy(K.variable(value = test_labels), K.variable(value = prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:12:12.713062Z",
     "iopub.status.busy": "2022-11-24T08:12:12.712489Z",
     "iopub.status.idle": "2022-11-24T08:12:13.090225Z",
     "shell.execute_reply": "2022-11-24T08:12:13.089376Z",
     "shell.execute_reply.started": "2022-11-24T08:12:12.713025Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('vgg16-model.h5')\n",
    "# model.save_weights('vgg16-w-model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
