{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:16.845286Z",
     "iopub.status.busy": "2022-11-20T18:14:16.844851Z",
     "iopub.status.idle": "2022-11-20T18:14:24.287963Z",
     "shell.execute_reply": "2022-11-20T18:14:24.287157Z",
     "shell.execute_reply.started": "2022-11-20T18:14:16.845207Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:24.290556Z",
     "iopub.status.busy": "2022-11-20T18:14:24.289736Z",
     "iopub.status.idle": "2022-11-20T18:14:25.133570Z",
     "shell.execute_reply": "2022-11-20T18:14:25.132706Z",
     "shell.execute_reply.started": "2022-11-20T18:14:24.290490Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset_information/Data_Entry_2017.csv')\n",
    "\n",
    "diseases = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n",
    "#Number diseases\n",
    "for disease in diseases :\n",
    "    df[disease] = df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:25.135480Z",
     "iopub.status.busy": "2022-11-20T18:14:25.135026Z",
     "iopub.status.idle": "2022-11-20T18:14:28.581595Z",
     "shell.execute_reply": "2022-11-20T18:14:28.579752Z",
     "shell.execute_reply.started": "2022-11-20T18:14:25.135436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images found: 112120\n"
     ]
    }
   ],
   "source": [
    "all_image_paths = {os.path.basename(x): x for x in glob(os.path.join('.', 'images', '*.png'))}\n",
    "print('Images found:', len(all_image_paths))\n",
    "df['Path'] = df['Image Index'].map(all_image_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.584196Z",
     "iopub.status.busy": "2022-11-20T18:14:28.583705Z",
     "iopub.status.idle": "2022-11-20T18:14:28.633016Z",
     "shell.execute_reply": "2022-11-20T18:14:28.632140Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.584157Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = df[diseases].to_numpy()\n",
    "files_list = df['Path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.634923Z",
     "iopub.status.busy": "2022-11-20T18:14:28.634416Z",
     "iopub.status.idle": "2022-11-20T18:14:28.656209Z",
     "shell.execute_reply": "2022-11-20T18:14:28.655161Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.634884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labelB = (df[diseases].sum(axis=1)>0).tolist()\n",
    "labelB = np.array(labelB, dtype=int)\n",
    "print(labelB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.658006Z",
     "iopub.status.busy": "2022-11-20T18:14:28.657651Z",
     "iopub.status.idle": "2022-11-20T18:14:28.722816Z",
     "shell.execute_reply": "2022-11-20T18:14:28.721828Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.657970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 75120  Testing: 37000\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df,test_size = 0.33,random_state = 2018)\n",
    "print(f'Training : {train_df.shape[0]}  Testing: {test_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.724637Z",
     "iopub.status.busy": "2022-11-20T18:14:28.724231Z",
     "iopub.status.idle": "2022-11-20T18:14:28.746734Z",
     "shell.execute_reply": "2022-11-20T18:14:28.745847Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.724597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9733\n"
     ]
    }
   ],
   "source": [
    "patient_train = set(train_df[\"Patient ID\"].values)\n",
    "patient_test  = set(test_df[\"Patient ID\"].values)\n",
    "\n",
    "leakage_patient = patient_train.intersection(patient_test)\n",
    "print(len(leakage_patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.748115Z",
     "iopub.status.busy": "2022-11-20T18:14:28.747789Z",
     "iopub.status.idle": "2022-11-20T18:14:28.780271Z",
     "shell.execute_reply": "2022-11-20T18:14:28.779464Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.748069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.2656283280085197\n",
      "75120\n",
      "19954\n",
      "\n",
      "Test\n",
      "0.18975675675675677\n",
      "37000\n",
      "7021\n"
     ]
    }
   ],
   "source": [
    "train_without_leakage = train_df[~train_df[\"Patient ID\"].isin(leakage_patient)]\n",
    "\n",
    "print(\"Train\")\n",
    "print(len(train_without_leakage) / len(train_df))\n",
    "print(len(train_df))\n",
    "print(len(train_without_leakage))\n",
    "\n",
    "print()\n",
    "print(\"Test\")\n",
    "test_without_leakage = test_df[~test_df[\"Patient ID\"].isin(leakage_patient)]\n",
    "print(len(test_without_leakage) / len(test_df))\n",
    "print(len(test_df))\n",
    "print(len(test_without_leakage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.782227Z",
     "iopub.status.busy": "2022-11-20T18:14:28.781614Z",
     "iopub.status.idle": "2022-11-20T18:14:28.787767Z",
     "shell.execute_reply": "2022-11-20T18:14:28.786809Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.782191Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = test_without_leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.791446Z",
     "iopub.status.busy": "2022-11-20T18:14:28.790835Z",
     "iopub.status.idle": "2022-11-20T18:14:28.832962Z",
     "shell.execute_reply": "2022-11-20T18:14:28.832072Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.791405Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.834726Z",
     "iopub.status.busy": "2022-11-20T18:14:28.834279Z",
     "iopub.status.idle": "2022-11-20T18:14:28.841135Z",
     "shell.execute_reply": "2022-11-20T18:14:28.840060Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.834686Z"
    }
   },
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path, shape):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=shape)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)/255\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths, shape):\n",
    "    list_of_tensors = [path_to_tensor(img_path, shape) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:14:28.843442Z",
     "iopub.status.busy": "2022-11-20T18:14:28.842486Z",
     "iopub.status.idle": "2022-11-20T18:47:41.789734Z",
     "shell.execute_reply": "2022-11-20T18:47:41.788829Z",
     "shell.execute_reply.started": "2022-11-20T18:14:28.843387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▌                                                    | 23463/60096 [07:03<12:33, 48.59it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpaths_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m valid_tensors \u001b[38;5;241m=\u001b[39m paths_to_tensor(valid_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(), shape \u001b[38;5;241m=\u001b[39m img_shape)\n\u001b[0;32m      4\u001b[0m test_tensors \u001b[38;5;241m=\u001b[39m paths_to_tensor(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(), shape \u001b[38;5;241m=\u001b[39m img_shape)\n",
      "Cell \u001b[1;32mIn [11], line 10\u001b[0m, in \u001b[0;36mpaths_to_tensor\u001b[1;34m(img_paths, shape)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpaths_to_tensor\u001b[39m(img_paths, shape):\n\u001b[1;32m---> 10\u001b[0m     list_of_tensors \u001b[38;5;241m=\u001b[39m [path_to_tensor(img_path, shape) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(img_paths)]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(list_of_tensors)\n",
      "Cell \u001b[1;32mIn [11], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpaths_to_tensor\u001b[39m(img_paths, shape):\n\u001b[1;32m---> 10\u001b[0m     list_of_tensors \u001b[38;5;241m=\u001b[39m [\u001b[43mpath_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(img_paths)]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(list_of_tensors)\n",
      "Cell \u001b[1;32mIn [11], line 5\u001b[0m, in \u001b[0;36mpath_to_tensor\u001b[1;34m(img_path, shape)\u001b[0m\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(img_path, target_size\u001b[38;5;241m=\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:243\u001b[0m, in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    241\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m    242\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\u001b[38;5;241m.\u001b[39mimg_to_array(img, data_format\u001b[38;5;241m=\u001b[39mdata_format, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:309\u001b[0m, in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown data_format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m data_format)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# Numpy array x has format (height, width, channel)\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# or (channel, height, width)\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# but original PIL image has format (width, height, channel)\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_shape = (128, 128)\n",
    "train_tensors = paths_to_tensor(train_df['Path'].to_list(), shape = img_shape)\n",
    "valid_tensors = paths_to_tensor(valid_df['Path'].to_list(), shape = img_shape)\n",
    "test_tensors = paths_to_tensor(test_df['Path'].to_list(), shape = img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:41.792430Z",
     "iopub.status.busy": "2022-11-20T18:47:41.791141Z",
     "iopub.status.idle": "2022-11-20T18:47:41.807735Z",
     "shell.execute_reply": "2022-11-20T18:47:41.806804Z",
     "shell.execute_reply.started": "2022-11-20T18:47:41.792385Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = (train_df[diseases].sum(axis=1)>0).tolist()\n",
    "train_labels = np.array(train_labels, dtype=int)\n",
    "train_labels = train_labels[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:41.809661Z",
     "iopub.status.busy": "2022-11-20T18:47:41.809130Z",
     "iopub.status.idle": "2022-11-20T18:47:41.819862Z",
     "shell.execute_reply": "2022-11-20T18:47:41.819038Z",
     "shell.execute_reply.started": "2022-11-20T18:47:41.809624Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:41.821383Z",
     "iopub.status.busy": "2022-11-20T18:47:41.820997Z",
     "iopub.status.idle": "2022-11-20T18:47:41.831953Z",
     "shell.execute_reply": "2022-11-20T18:47:41.831141Z",
     "shell.execute_reply.started": "2022-11-20T18:47:41.821337Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_labels = (valid_df[diseases].sum(axis=1)>0).tolist()\n",
    "valid_labels = np.array(valid_labels, dtype=int)\n",
    "valid_labels =valid_labels[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:41.833816Z",
     "iopub.status.busy": "2022-11-20T18:47:41.833479Z",
     "iopub.status.idle": "2022-11-20T18:47:41.846054Z",
     "shell.execute_reply": "2022-11-20T18:47:41.845280Z",
     "shell.execute_reply.started": "2022-11-20T18:47:41.833782Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels = (test_df[diseases].sum(axis=1)>0).tolist()\n",
    "test_labels = np.array(test_labels, dtype=int)\n",
    "test_labels =test_labels[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:41.850212Z",
     "iopub.status.busy": "2022-11-20T18:47:41.849885Z",
     "iopub.status.idle": "2022-11-20T18:47:42.243965Z",
     "shell.execute_reply": "2022-11-20T18:47:42.243080Z",
     "shell.execute_reply.started": "2022-11-20T18:47:41.850155Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:42.247597Z",
     "iopub.status.busy": "2022-11-20T18:47:42.247308Z",
     "iopub.status.idle": "2022-11-20T18:47:46.512953Z",
     "shell.execute_reply": "2022-11-20T18:47:46.511157Z",
     "shell.execute_reply.started": "2022-11-20T18:47:42.247571Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=train_tensors.shape[1:])\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(50, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "\n",
    "# model.summary()\n",
    "# add_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:46.514579Z",
     "iopub.status.busy": "2022-11-20T18:47:46.514189Z",
     "iopub.status.idle": "2022-11-20T18:47:46.521143Z",
     "shell.execute_reply": "2022-11-20T18:47:46.520359Z",
     "shell.execute_reply.started": "2022-11-20T18:47:46.514541Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:46.523038Z",
     "iopub.status.busy": "2022-11-20T18:47:46.522436Z",
     "iopub.status.idle": "2022-11-20T18:47:46.534627Z",
     "shell.execute_reply": "2022-11-20T18:47:46.533737Z",
     "shell.execute_reply.started": "2022-11-20T18:47:46.522996Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:46.536281Z",
     "iopub.status.busy": "2022-11-20T18:47:46.535812Z",
     "iopub.status.idle": "2022-11-20T18:47:46.544975Z",
     "shell.execute_reply": "2022-11-20T18:47:46.544297Z",
     "shell.execute_reply.started": "2022-11-20T18:47:46.536244Z"
    }
   },
   "outputs": [],
   "source": [
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:46.546871Z",
     "iopub.status.busy": "2022-11-20T18:47:46.546475Z",
     "iopub.status.idle": "2022-11-20T18:47:46.562215Z",
     "shell.execute_reply": "2022-11-20T18:47:46.561450Z",
     "shell.execute_reply.started": "2022-11-20T18:47:46.546836Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(learning_rate=1e-4, decay=1e-6, momentum=0.9, nesterov=True), loss='binary_crossentropy', \n",
    "              metrics=[\n",
    "                  'accuracy',\n",
    "                  precision_threshold(threshold = 0.5), \n",
    "                  recall_threshold(threshold = 0.5), \n",
    "                  fbeta_score_threshold(beta=0.5, threshold = 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:46.563900Z",
     "iopub.status.busy": "2022-11-20T18:47:46.563395Z",
     "iopub.status.idle": "2022-11-20T18:47:46.574801Z",
     "shell.execute_reply": "2022-11-20T18:47:46.573983Z",
     "shell.execute_reply.started": "2022-11-20T18:47:46.563864Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "Epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "log = CSVLogger('saved_models/log_pretrained_CNN.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/pretrainedVGG.best.from_scratch.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T18:47:46.576574Z",
     "iopub.status.busy": "2022-11-20T18:47:46.576160Z",
     "iopub.status.idle": "2022-11-20T19:23:59.103058Z",
     "shell.execute_reply": "2022-11-20T19:23:59.102265Z",
     "shell.execute_reply.started": "2022-11-20T18:47:46.576509Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                        samplewise_center=False,  # set each sample mean to 0\n",
    "                        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                        samplewise_std_normalization=False,  # divide each input by its std\n",
    "                        zca_whitening=False,  # apply ZCA whitening\n",
    "                        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                        horizontal_flip=True,  # randomly flip images\n",
    "                        vertical_flip=False \n",
    ")\n",
    "\n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(train_tensors,train_labels, batch_size = batch_size),\n",
    "    steps_per_epoch = len(train_tensors) // batch_size,\n",
    "    validation_data = (valid_tensors, valid_labels),\n",
    "    validation_steps = len(valid_tensors) // batch_size,\n",
    "    epochs = Epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T19:23:59.104966Z",
     "iopub.status.busy": "2022-11-20T19:23:59.104609Z",
     "iopub.status.idle": "2022-11-20T19:24:03.154661Z",
     "shell.execute_reply": "2022-11-20T19:24:03.153807Z",
     "shell.execute_reply.started": "2022-11-20T19:23:59.104930Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "prediction = model.predict(test_tensors)\n",
    "\n",
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels), K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels), K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))\n",
    "\n",
    "K.eval(binary_accuracy(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "roc_auc_score(test_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T19:24:03.156658Z",
     "iopub.status.busy": "2022-11-20T19:24:03.155813Z",
     "iopub.status.idle": "2022-11-20T19:24:03.515748Z",
     "shell.execute_reply": "2022-11-20T19:24:03.514887Z",
     "shell.execute_reply.started": "2022-11-20T19:24:03.156617Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('vgg16-model.h5')\n",
    "model.save_weights('vgg16-w-model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
