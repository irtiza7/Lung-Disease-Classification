{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a937500a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:17:17.560168Z",
     "iopub.status.busy": "2022-12-13T00:17:17.559846Z",
     "iopub.status.idle": "2022-12-13T00:17:25.150281Z",
     "shell.execute_reply": "2022-12-13T00:17:25.149337Z",
     "shell.execute_reply.started": "2022-12-13T00:17:17.560092Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "from tensorflow.keras.applications import EfficientNetB6\n",
    "from tensorflow.keras.applications import EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fd1907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:17:25.165641Z",
     "iopub.status.busy": "2022-12-13T00:17:25.164854Z",
     "iopub.status.idle": "2022-12-13T00:17:25.183000Z",
     "shell.execute_reply": "2022-12-13T00:17:25.182025Z",
     "shell.execute_reply.started": "2022-12-13T00:17:25.165605Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_cm(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "def calculate_recall(tp, fp, fn, tn):\n",
    "    return (tp)/(tp + fn)\n",
    "\n",
    "def calculate_fallout(tp, fp, fn, tn):\n",
    "    return (fp)/(fp + tn)\n",
    "\n",
    "def calculate_fpr_tpr(y_true, y_pred):\n",
    "    tp, fp, fn, tn = calculate_cm(y_true, y_pred)\n",
    "    tpr = calculate_recall(tp, fp, fn, tn)\n",
    "    fpr = calculate_fallout(tp, fp, fn, tn)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434c1e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:17:25.186332Z",
     "iopub.status.busy": "2022-12-13T00:17:25.185867Z",
     "iopub.status.idle": "2022-12-13T00:19:20.252152Z",
     "shell.execute_reply": "2022-12-13T00:19:20.251133Z",
     "shell.execute_reply.started": "2022-12-13T00:17:25.186299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 112120/112120 [01:20<00:00, 1395.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Image Paths</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>.\\images\\00000001_000.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>.\\images\\00000001_001.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>.\\images\\00000001_002.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>.\\images\\00000002_000.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>.\\images\\00000003_000.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index                Image Paths  Effusion  Infiltration  \\\n",
       "0  00000001_000.png  .\\images\\00000001_000.png       0.0           0.0   \n",
       "1  00000001_001.png  .\\images\\00000001_001.png       0.0           0.0   \n",
       "2  00000001_002.png  .\\images\\00000001_002.png       1.0           0.0   \n",
       "3  00000002_000.png  .\\images\\00000002_000.png       0.0           0.0   \n",
       "4  00000003_000.png  .\\images\\00000003_000.png       0.0           0.0   \n",
       "\n",
       "   Pleural_Thickening  Emphysema  Mass  Edema  Consolidation  Pneumothorax  \\\n",
       "0                 0.0        0.0   0.0    0.0            0.0           0.0   \n",
       "1                 0.0        1.0   0.0    0.0            0.0           0.0   \n",
       "2                 0.0        0.0   0.0    0.0            0.0           0.0   \n",
       "3                 0.0        0.0   0.0    0.0            0.0           0.0   \n",
       "4                 0.0        0.0   0.0    0.0            0.0           0.0   \n",
       "\n",
       "   Pneumonia  Atelectasis  Nodule  Hernia  Cardiomegaly  Fibrosis  No Finding  \n",
       "0        0.0          0.0     0.0     0.0           1.0       0.0         0.0  \n",
       "1        0.0          0.0     0.0     0.0           1.0       0.0         0.0  \n",
       "2        0.0          0.0     0.0     0.0           1.0       0.0         0.0  \n",
       "3        0.0          0.0     0.0     0.0           0.0       0.0         1.0  \n",
       "4        0.0          0.0     0.0     1.0           0.0       0.0         0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = {os.path.basename(x): x for x in glob(os.path.join('..', 'input', 'data', 'images*', 'images', '*.png'))}\n",
    "df = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")\n",
    "\n",
    "df = df.drop(\n",
    "    columns = [\n",
    "        \"Follow-up #\", \n",
    "        \"Patient ID\", \n",
    "        \"Patient Age\", \n",
    "        \"Patient Gender\", \n",
    "        \"OriginalImage[Width\",\n",
    "        \"Height]\",\n",
    "        \"OriginalImagePixelSpacing[x\",\n",
    "        \"y]\",\n",
    "#         \"Unnamed: 11\",\n",
    "        \"View Position\"\n",
    "    ], \n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "df[\"Image Paths\"] = \" \"\n",
    "for row_index in tqdm(range(len(df)), ncols = 100):\n",
    "    img_name = df.iloc[row_index][0]\n",
    "    path = image_paths[img_name]\n",
    "    df[\"Image Paths\"][row_index] = path\n",
    "\n",
    "unique_labels = set(itertools.chain.from_iterable(df[\"Finding Labels\"].apply(lambda x : x.split('|')).values)) \n",
    "one_hot_labels = pd.DataFrame(0.0, index = np.arange(len(df)), columns = unique_labels)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    labels = row[\"Finding Labels\"].split('|')\n",
    "    for label in labels:\n",
    "        one_hot_labels.iloc[index][label] = 1.0\n",
    "\n",
    "df = pd.concat([df, one_hot_labels], axis = 1)\n",
    "df = df.drop(columns = [\"Finding Labels\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5931d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:19:20.254034Z",
     "iopub.status.busy": "2022-12-13T00:19:20.253633Z",
     "iopub.status.idle": "2022-12-13T00:19:20.314915Z",
     "shell.execute_reply": "2022-12-13T00:19:20.313715Z",
     "shell.execute_reply.started": "2022-12-13T00:19:20.253972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 80726\n",
      "Validation Samples: 8970\n",
      "Testing Samples: 22424\n"
     ]
    }
   ],
   "source": [
    "# df_train, df_test = train_test_split(dataset_info.sample(n = 60000), test_size = 0.20, random_state = 142)\n",
    "df_train, df_test = train_test_split(df, test_size = 0.20, random_state = 0)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.10, random_state = 0)\n",
    "\n",
    "print(f\"Training Samples: {len(df_train)}\\nValidation Samples: {len(df_val)}\\nTesting Samples: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0d392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = [\n",
    "    \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Effusion\", \"Emphysema\", \"Fibrosis\", \"Hernia\", \n",
    "    \"Infiltration\", \"Mass\", \"No Finding\", \"Nodule\", \"Pleural_Thickening\", \"Pneumonia\",\"Pneumothorax\"\n",
    "]\n",
    "IMAGE_SIZE = (224, 224,)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "\n",
    "BETA_FOR_BIASED_RECALL = 1.3\n",
    "BETA_FOR_BIASED_PRECISION = 0.7\n",
    "BETA_WITH_NO_BIAS = 1\n",
    "\n",
    "THRESHOLDS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "METRICS = [\n",
    "  tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "  tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "  tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "  tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "  tf.keras.metrics.BinaryAccuracy(name = 'binary_accuracy'),\n",
    "  tf.keras.metrics.Precision(name = 'precision', thresholds = 0.3),\n",
    "  tf.keras.metrics.Recall(name = 'recall', thresholds = 0.3),\n",
    "  tf.keras.metrics.AUC(name = 'auc', multi_label = True, num_labels = 15, thresholds = THRESHOLDS),\n",
    "  tf.keras.metrics.AUC(name = 'prc', curve = 'PR')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f7733e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:19:20.325954Z",
     "iopub.status.busy": "2022-12-13T00:19:20.325522Z",
     "iopub.status.idle": "2022-12-13T00:19:20.334253Z",
     "shell.execute_reply": "2022-12-13T00:19:20.333194Z",
     "shell.execute_reply.started": "2022-12-13T00:19:20.325918Z"
    }
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(image_generator, dataframe):\n",
    "    df_gen = image_generator.flow_from_dataframe(\n",
    "        dataframe,\n",
    "        x_col = \"Image Paths\", \n",
    "        y_col = dataframe.columns[2:],\n",
    "        target_size = IMAGE_SIZE,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'raw',\n",
    "        shuffle = False,\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n",
    "    return df_gen\n",
    "\n",
    "def sharpen_image(image):\n",
    "    sharp_kernel = np.array(\n",
    "        [\n",
    "            [0, -1, 0], \n",
    "            [-1, 5, -1], \n",
    "            [0, -1, 0]\n",
    "        ])\n",
    "    output = cv2.filter2D(src = image, ddepth = -1, kernel = sharp_kernel)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7442e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    preprocessing_function = sharpen_image,\n",
    "    zca_whitening = False,\n",
    "    rotation_range = 20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True\n",
    ")\n",
    "val_data_generator = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    preprocessing_function = sharpen_image\n",
    ")\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    preprocessing_function = sharpen_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1765596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80726 validated image filenames.\n",
      "Found 8970 validated image filenames.\n",
      "Found 22424 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(image_generator = train_data_generator, dataframe = df_train)\n",
    "valid_gen = flow_from_dataframe(image_generator = val_data_generator, dataframe = df_val)\n",
    "test_gen = flow_from_dataframe(image_generator = test_data_generator, dataframe = df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa99947b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:20:48.394372Z",
     "iopub.status.busy": "2022-12-13T00:20:48.393929Z",
     "iopub.status.idle": "2022-12-13T00:20:48.400620Z",
     "shell.execute_reply": "2022-12-13T00:20:48.399561Z",
     "shell.execute_reply.started": "2022-12-13T00:20:48.394335Z"
    }
   },
   "outputs": [],
   "source": [
    "SGD_optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate = 0.0001, \n",
    "    decay = 1e-6, \n",
    "    momentum = 0.9, \n",
    "    nesterov = True\n",
    ")\n",
    "adam_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.0001,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9075398",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0,\n",
    "    patience = 4,\n",
    "    verbose = 1,\n",
    "    mode = 'auto',\n",
    "    baseline = None,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f6a8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "class MultiLabelCrossEntropy:\n",
    "    \"\"\"\n",
    "    Weight Cross Entropy Loss.\n",
    "    \n",
    "    For each class we will found two weights corresponding to the positive and negative frequency of our sample data.\n",
    "    These weights will manage the way we update our network. And this has for objectives to manage the unbalanced class issue.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, labels : DataFrame, epsilon = 1e-7):\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Get the size of the data\n",
    "        self.N = labels.shape[0]\n",
    "        \n",
    "        # Get the frequency occurence for each class\n",
    "        self.freq_pos = np.sum(labels == 1, axis=0) / self.N\n",
    "        self.freq_neg = np.sum(labels == 0, axis=0) / self.N\n",
    "        \n",
    "        # Set the loss weights for each labels \n",
    "        self.pos_weights = self.freq_neg\n",
    "        self.neg_weights = self.freq_pos\n",
    "        \n",
    "    def contribution(self):\n",
    "        \"\"\"\n",
    "        Get the weights' contribution for each labels.\n",
    "        \n",
    "        Returns :\n",
    "            - double : Positive contribution\n",
    "            - double : Negative contribution\n",
    "        \"\"\"\n",
    "        return self.freq_pos * self.pos_weights, self.freq_neg * self.neg_weights\n",
    "        \n",
    "        \n",
    "    def loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Return weighted loss value. \n",
    "        \"\"\"\n",
    "        # Initialize loss to zero\n",
    "        loss = 0.0\n",
    "        \n",
    "        for i in range(len(self.pos_weights)):\n",
    "            loss += (\n",
    "                -1 * K.mean(self.pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + self.epsilon))\n",
    "                    ) + (\n",
    "                -1 * K.mean(self.neg_weights[i] * (1 - y_true[:,i]) * K.log(1 - y_pred[:,i] + self.epsilon))\n",
    "                    )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b365f576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75682</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72229</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55936</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94711</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83935</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111025</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90066</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80726 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Effusion  Infiltration  Pleural_Thickening  Emphysema  Mass  Edema  \\\n",
       "75682        0.0           0.0                 0.0        0.0   0.0    1.0   \n",
       "103217       0.0           0.0                 0.0        0.0   0.0    0.0   \n",
       "72229        1.0           1.0                 0.0        0.0   0.0    0.0   \n",
       "39356        0.0           1.0                 0.0        0.0   0.0    0.0   \n",
       "55936        0.0           0.0                 0.0        0.0   1.0    0.0   \n",
       "...          ...           ...                 ...        ...   ...    ...   \n",
       "94711        0.0           0.0                 0.0        0.0   0.0    0.0   \n",
       "83935        0.0           0.0                 0.0        0.0   0.0    0.0   \n",
       "88514        1.0           0.0                 0.0        0.0   0.0    0.0   \n",
       "111025       0.0           0.0                 0.0        0.0   0.0    0.0   \n",
       "90066        0.0           0.0                 0.0        0.0   0.0    0.0   \n",
       "\n",
       "        Consolidation  Pneumothorax  Pneumonia  Atelectasis  Nodule  Hernia  \\\n",
       "75682             0.0           0.0        1.0          0.0     0.0     0.0   \n",
       "103217            0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "72229             0.0           0.0        0.0          1.0     0.0     0.0   \n",
       "39356             0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "55936             0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "...               ...           ...        ...          ...     ...     ...   \n",
       "94711             0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "83935             0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "88514             0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "111025            0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "90066             0.0           0.0        0.0          0.0     0.0     0.0   \n",
       "\n",
       "        Cardiomegaly  Fibrosis  No Finding  \n",
       "75682            0.0       0.0         0.0  \n",
       "103217           0.0       0.0         1.0  \n",
       "72229            0.0       0.0         0.0  \n",
       "39356            0.0       0.0         0.0  \n",
       "55936            0.0       0.0         0.0  \n",
       "...              ...       ...         ...  \n",
       "94711            0.0       0.0         1.0  \n",
       "83935            0.0       0.0         1.0  \n",
       "88514            0.0       0.0         0.0  \n",
       "111025           0.0       0.0         1.0  \n",
       "90066            0.0       0.0         1.0  \n",
       "\n",
       "[80726 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_loss = MultiLabelCrossEntropy(df_train[unique_labels])\n",
    "# df_train[unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37cd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_contribution, neg_contribution = cross_entropy_loss.contribution()\n",
    "# print(pos_contribution, neg_contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd8826b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:20:48.414043Z",
     "iopub.status.busy": "2022-12-13T00:20:48.413675Z",
     "iopub.status.idle": "2022-12-13T00:20:48.437638Z",
     "shell.execute_reply": "2022-12-13T00:20:48.436609Z",
     "shell.execute_reply.started": "2022-12-13T00:20:48.414006Z"
    }
   },
   "outputs": [],
   "source": [
    "channels = (3,)\n",
    "input_shape = IMAGE_SIZE + channels\n",
    "img_input = Input(shape = input_shape)\n",
    "\n",
    "MODEL_NAME = \"Xception\"\n",
    "base_model = Xception(\n",
    "    input_shape = input_shape,\n",
    "    include_top = False,\n",
    "    weights = \"imagenet\"\n",
    ")\n",
    "\n",
    "custom_classifier = Sequential()\n",
    "custom_classifier.add(GlobalAveragePooling2D(input_shape = base_model.output_shape[1:]))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "\n",
    "custom_classifier.add(Dense(256))\n",
    "custom_classifier.add(BatchNormalization())\n",
    "custom_classifier.add(Activation('relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "\n",
    "custom_classifier.add(Dense(50))\n",
    "custom_classifier.add(BatchNormalization())\n",
    "custom_classifier.add(Activation('relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "\n",
    "custom_classifier.add(Dense(15, activation = \"sigmoid\"))\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = custom_classifier(base_model.output))\n",
    "# model.load_weights(f\"./saved_weights/{MODEL_NAME}_{EPOCHS}_weights.h5\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = adam_optimizer,\n",
    "    loss = cross_entropy_loss.loss,\n",
    "    metrics = METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9397b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:20:48.439347Z",
     "iopub.status.busy": "2022-12-13T00:20:48.439039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  42/5045 [..............................] - ETA: 57:41 - loss: 1.3495 - tp: 420.0000 - fp: 4260.0000 - tn: 4968.0000 - fn: 432.0000 - binary_accuracy: 0.5345 - precision: 0.0867 - recall: 0.8404 - auc: 0.5132 - prc: 0.0906"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,1536,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_1/block14_sepconv2/separable_conv2d/Conv2DBackpropInput (defined at <ipython-input-27-cb9c09844d0f>:11) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_32311]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-cb9c09844d0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1987\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1989\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1991\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,1536,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_1/block14_sepconv2/separable_conv2d/Conv2DBackpropInput (defined at <ipython-input-27-cb9c09844d0f>:11) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_32311]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    epochs = EPOCHS,\n",
    "    generator = train_gen,\n",
    "    steps_per_epoch = train_gen.n / train_gen.batch_size,\n",
    "    validation_data = valid_gen,\n",
    "    validation_steps = valid_gen.n / valid_gen.batch_size,\n",
    "    shuffle = False,\n",
    "    verbose = 1,\n",
    "    callbacks = None\n",
    ")\n",
    "\n",
    "print(f\"\\nTime Taken: {(time.time() - start_time) / 3600 : .4f} Hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['loss'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_loss'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['binary_accuracy'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_binary_accuracy'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Binary Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['recall'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_recall'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['precision'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_precision'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['auc'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_auc'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['prc'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_prc'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation PRC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('PRC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a223f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"./saved_weights/{MODEL_NAME}_{EPOCHS}_weights.h5\")\n",
    "evaluation = model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f91788",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluation[0]\n",
    "TP = evaluation[1]\n",
    "FP = evaluation[2]\n",
    "TN = evaluation[3]\n",
    "FN = evaluation[4]\n",
    "binary_accuracy = evaluation[5] * 100\n",
    "auc = evaluation[8] * 100\n",
    "auc_pr = evaluation[9] * 100\n",
    "\n",
    "specificity = (TN / (TN + FP)) * 100\n",
    "recall = (TP / (TP + FN)) * 100\n",
    "precision = (TP / (TP + FP)) * 100\n",
    "f1_score = (2 * recall * precision) / (recall + precision)\n",
    "\n",
    "print(f\"Testing Loss: \\t\\t{test_loss}\\n\")\n",
    "print(f\"True Positives: \\t{TP}\\nFalse Positives: \\t{FP}\\nTrue Negatives: \\t{TN}\\nFalse Negatives: \\t{FN}\\n\")\n",
    "print(f\"Binary Accuracy: \\t{binary_accuracy}\")\n",
    "print(f\"Average Recall: \\t{recall}\\nAverage Precision: \\t{precision}\\nF1-Score: \\t\\t{f1_score}\\nAverage Specificity: \\t{specificity}\\n\")\n",
    "print(f\"AUC: \\t\\t\\t{auc}\\nAUC-PR: \\t\\t{auc_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "predictions = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score\n",
    "    \n",
    "def print_results(beta, threshold, test_labels, prediction):\n",
    "    accuracy = K.eval(binary_accuracy(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    precision = K.eval(precision_threshold(threshold = threshold)(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    recall = K.eval(recall_threshold(threshold = threshold)(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    f1_score = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    print(f\"BETA: {beta}, THRESHOLD: {threshold}\")\n",
    "    print (f\"Binary Accuracy: \\t{accuracy * 100} % \\nRecall: \\t\\t{recall * 100} % \\nPrecision: \\t\\t{precision * 100} % \\nF1-Score: \\t\\t{f1_score * 100} %\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b16d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for label in test_gen.labels:\n",
    "    test_labels.append(label)\n",
    "\n",
    "# # Results with F Score giving more weightage to Recall\n",
    "# for threshold in THRESHOLDS:\n",
    "#     print_results(beta = BETA_FOR_BIASED_RECALL, threshold = threshold, test_labels = test_labels, prediction = predictions)\n",
    "\n",
    "# # Results with F Score giving more weightage to Precision\n",
    "# for threshold in THRESHOLDS:\n",
    "#     print_results(beta = BETA_FOR_BIASED_PRECISION, threshold = threshold, test_labels = test_labels, prediction = predictions)\n",
    "\n",
    "# Results with F Score giving equal weightage to Recall and Precision\n",
    "for threshold in THRESHOLDS:\n",
    "    print_results(beta = BETA_WITH_NO_BIAS, threshold = threshold, test_labels = test_labels, prediction = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cddada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names,)\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    axes.set_ylabel('True label')\n",
    "    axes.set_xlabel('Predicted label')\n",
    "    axes.set_title(\"Confusion Matrix - \" + class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "y_test = test_gen.labels\n",
    "y_predicted = (predictions >= threshold).astype(int)\n",
    "confusion_matrix = multilabel_confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize=(22, 10))\n",
    "for axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_LABELS):\n",
    "    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9116981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "colors = cycle(['blue', 'red', 'green', 'black', 'purple', 'magenta', 'cyan', 'orange', 'teal', 'darkgreen'])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "lw = 2\n",
    "\n",
    "for i in range(len(CLASS_LABELS)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions[:, i])\n",
    "    roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "avg_auc = 0\n",
    "for auc_value in roc_auc.values():\n",
    "    avg_auc += auc_value\n",
    "print(f\"[{MODEL_NAME} with {EPOCHS} Epochs] - Average AUC: {avg_auc / 15}\")\n",
    "    \n",
    "for i, color in zip(range(len(CLASS_LABELS)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color = color, lw = 2, label = '{0} (AUC = {1:0.2f})'''.format(CLASS_LABELS[i], roc_auc[i]))\n",
    "\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC - {MODEL_NAME} with {EPOCHS} Epochs')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602a1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
