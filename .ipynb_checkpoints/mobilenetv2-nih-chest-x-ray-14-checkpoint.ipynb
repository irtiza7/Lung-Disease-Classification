{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0763325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n1 -r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf8cde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations\n",
    "import cv2\n",
    "\n",
    "import gc as Garbase_Collector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02152e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f11a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 36000\n",
      "Validation Samples: 4000\n",
      "Testing Samples: 10000\n"
     ]
    }
   ],
   "source": [
    "dataset_info = pd.read_csv('.\\\\meta_data.csv')\n",
    "\n",
    "df_train, df_test = train_test_split(dataset_info.sample(n = 50000), test_size = 0.20, random_state = 42)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.10, random_state = 42)\n",
    "\n",
    "print(f\"Training Samples: {len(df_train)}\\nValidation Samples: {len(df_val)}\\nTesting Samples: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e27e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore', category = np.VisibleDeprecationWarning)\n",
    "\n",
    "def get_data(df, img_size):\n",
    "    data = []\n",
    "    \n",
    "    paths = df.Image_Path.values\n",
    "    labels = df.Binary_Image_Labels.values\n",
    "    \n",
    "    for path, label in tqdm(zip(paths, labels), desc = \"Progress\"):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        data.append([img, label])\n",
    "        \n",
    "    return np.array(data, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0fd1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128, 128)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea4a70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 36000it [09:52, 60.73it/s]\n",
      "Progress: 4000it [01:11, 55.90it/s]\n",
      "Progress: 10000it [02:43, 61.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(df_train, IMAGE_SIZE)\n",
    "del df_train\n",
    "val_data = get_data(df_val, IMAGE_SIZE)\n",
    "del df_val\n",
    "test_data = get_data(df_test, IMAGE_SIZE)\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86bfd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = [], [], [], []\n",
    "\n",
    "for feature, label in train_data:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "del train_data\n",
    "\n",
    "for feature, label in val_data:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "\n",
    "del val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734da492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Garbase_Collector.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a50b1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "img_size = IMAGE_SIZE[0]\n",
    "x_train = np.array(x_train) / 255\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "x_val = np.array(x_val) / 255\n",
    "x_val.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b4bcf2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.59 GiB for an array with shape (36000, 128, 128, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      3\u001b[0m data_generator \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      4\u001b[0m     featurewise_center \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# set input mean to 0 over the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     samplewise_center \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# set each sample mean to 0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     vertical_flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# randomly flip images\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[43mdata_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:952\u001b[0m, in \u001b[0;36mImageDataGenerator.fit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    950\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m--> 952\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale:\n\u001b[0;32m    954\u001b[0m     x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\lib\\function_base.py:959\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(a, order, subok)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_copy_dispatcher)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(a, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m    Return an array copy of the given object.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    957\u001b[0m \n\u001b[0;32m    958\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.59 GiB for an array with shape (36000, 128, 128, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center = False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization = False,  # divide each input by its std\n",
    "    zca_whitening = False,  # apply ZCA whitening\n",
    "    rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.2, # Randomly zoom image \n",
    "    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True,  # randomly flip images\n",
    "    vertical_flip = False  # randomly flip images\n",
    ")\n",
    "\n",
    "data_generator.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdff764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa791ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_v2 = MobileNetV2(input_shape =  (128, 128, 3), include_top = False, weights = \"imagenet\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(mobile_net_v2)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(15, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = [\n",
    "        'accuracy', \n",
    "        'binary_accuracy', \n",
    "        'mae', \n",
    "#         precision_threshold(threshold = 0.5), \n",
    "#         recall_threshold(threshold = 0.5), \n",
    "#         fbeta_score_threshold(beta=0.5, threshold = 0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train, epochs = 10 , validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456817c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(lr=0.000001)\n",
    "# model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(x_train,steps_per_epoch = 100, validation_data = (x_val,y_val), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea12bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
