{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import gc\n","import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from glob import glob\n","from tqdm import tqdm\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n","from keras.preprocessing import image                  \n","from sklearn.utils import shuffle\n","from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n","from keras.models import Sequential, Model\n","from keras.layers import BatchNormalization\n","from keras import regularizers, applications, optimizers, initializers\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def binary_accuracy(y_true, y_pred):\n","    return K.mean(K.equal(y_true, K.round(y_pred)))\n","\n","def precision_threshold(threshold = 0.5):\n","    def precision(y_true, y_pred):\n","        threshold_value = threshold\n","        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n","        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(y_pred)\n","        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n","        return precision_ratio\n","    return precision\n","\n","def recall_threshold(threshold = 0.5):\n","    def recall(y_true, y_pred):\n","        threshold_value = threshold\n","        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n","        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.clip(y_true, 0, 1))\n","        recall_ratio = true_positives / (possible_positives + K.epsilon())\n","        return recall_ratio\n","    return recall\n","\n","def fbeta_score_threshold(beta = 1, threshold = 0.5):\n","    def fbeta_score(y_true, y_pred):\n","        threshold_value = threshold\n","        beta_value = beta\n","        p = precision_threshold(threshold_value)(y_true, y_pred)\n","        r = recall_threshold(threshold_value)(y_true, y_pred)\n","        bb = beta_value ** 2\n","        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n","        return fbeta_score\n","    return fbeta_score"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["diseases = [\n","    'Cardiomegaly','Emphysema','Effusion',\n","    'Hernia','Nodule','Pneumothorax',\n","    'Atelectasis','Pleural_Thickening',\n","    'Mass','Edema','Consolidation',\n","    'Infiltration','Fibrosis','Pneumonia'\n","]\n","\n","# dataset_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\n","dataset_df = pd.read_csv('./dataset_information/Data_Entry_2017.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Applying One Hot Encoding to Labels\n","for disease in diseases:\n","    dataset_df[disease] = dataset_df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Samples Found: 112120\n"]}],"source":["image_labels = dataset_df[diseases].to_numpy()\n","image_paths = {\n","    # os.path.basename(x): x for x in glob(os.path.join('..', 'input', 'data', 'images*', 'images', '*.png'))\n","    os.path.basename(x): x for x in glob(os.path.join('.', 'images', '*.png'))\n","}\n","\n","print(f\"Samples Found: {len(image_paths)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Storing path to each image against image name in the dataframe\n","dataset_df['Image Path'] = dataset_df['Image Index'].map(image_paths.get)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["images_list = dataset_df['Image Path'].tolist()\n","\n","labelB = (dataset_df[diseases].sum(axis = 1) > 0).tolist()\n","labelB = np.array(labelB, dtype = int)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def read_image_to_tensor(path, shape):\n","    # Loads RGB image to PIL format\n","    img = image.load_img(path, target_size = shape)\n","    \n","    # Convert PIL image to 3D tensor of specific shape\n","    # and normalizes it by dividing each pixel by 255\n","    normalized_image_tensor = image.img_to_array(img) / 255\n","    \n","    # Convert 3D tensor to 4D tensor with specific shape \n","    # (1, shape, 3) and return it\n","    return np.expand_dims(normalized_image_tensor, axis = 0)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def image_to_array(paths, shape):\n","    images_arrays = [read_image_to_tensor(path, shape) for path in tqdm(paths, desc = \"Progress\", ncols = 100)]\n","    return np.vstack(images_arrays)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Defining some hyper-parameters\n","IMAGE_SHAPE = (75, 75)\n","EPOCHS = 5\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Progress: 100%|███████████████████████████████████████████████| 85000/85000 [23:00<00:00, 61.57it/s]\n","\n","Progress: 100%|███████████████████████████████████████████████| 10000/10000 [02:37<00:00, 63.63it/s]\n","\n","Progress: 100%|███████████████████████████████████████████████| 17120/17120 [04:35<00:00, 62.13it/s]\n"]}],"source":["# Samples in Training Set: 70%\n","# Samples in Validation Set: 10%\n","\n","# Storing labels of samples for each set\n","train_labels = labelB[ : 78484][ : , np.newaxis]\n","valid_labels = labelB[78484 : 89696][ : , np.newaxis]\n","\n","# Storing arrays of samples for each set\n","training_samples = image_to_array(images_list[ : 78484], shape = IMAGE_SHAPE)\n","validation_samples = image_to_array(images_list[78484 : 89696], shape = IMAGE_SHAPE)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n","\n","258080768/258076736 [==============================] - 538s 2us/step\n","\n","258088960/258076736 [==============================] - 538s 2us/step\n"]}],"source":["# Creating a model with MobileNetV2 as base.\n","m_net = MobileNetV2(\n","    weights = 'imagenet',\n","    include_top = False,\n","    input_shape = training_samples.shape[1 : ]\n",")\n","\n","custom_classifier = Sequential()\n","custom_classifier.add(GlobalAveragePooling2D(input_shape = m_net.output_shape[1 : ]))\n","custom_classifier.add(Dropout(0.2))\n","custom_classifier.add(Dense(256, activation = 'relu'))\n","custom_classifier.add(Dropout(0.2))\n","custom_classifier.add(Dense(50, activation = 'relu'))\n","custom_classifier.add(Dropout(0.2))\n","custom_classifier.add(Dense(1, activation = 'sigmoid'))\n","\n","model = Model(inputs = m_net.input, outputs = custom_classifier(m_net.output))\n","# model.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Defining 2 optimizers to test the model with.\n","\n","SGD_optimizer = tf.keras.optimizers.SGD(\n","    learning_rate = 1e-4, \n","    decay = 1e-6, \n","    momentum = 0.9, \n","    nesterov = True\n",")\n","adam_optimizer = tf.keras.optimizers.Adam(\n","    learning_rate = 0.001,\n","    beta_1 = 0.9,\n","    beta_2 = 0.999,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Defining object for augmentation \n","\n","train_datagen = ImageDataGenerator(\n","    featurewise_center = False,  # set input mean to 0 over the dataset\n","    samplewise_center = False,  # set each sample mean to 0\n","    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n","    samplewise_std_normalization = False,  # divide each input by its std\n","    zca_whitening = False,  # apply ZCA whitening\n","    rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n","    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n","    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n","    horizontal_flip = True,  # randomly flip images\n","    vertical_flip = False \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log = CSVLogger('saved_models/log_pretrained_CNN.csv')\n","checkpointer = ModelCheckpoint(filepath='saved_models/pretrainedVGG.best.from_scratch.hdf5', verbose=1, save_best_only=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"scrolled":true},"outputs":[],"source":["# Compiling model with loss function, optimizer and metrics\n","\n","model.compile(\n","    optimizer = SGD_optimizer,\n","    loss = 'binary_crossentropy',\n","    metrics = [\n","        'accuracy',\n","        precision_threshold(threshold = 0.5), \n","        recall_threshold(threshold = 0.5), \n","        fbeta_score_threshold(beta=0.5, threshold = 0.5)\n","    ]\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\n","2656/2656 [==============================] - 1466s 552ms/step - loss: 0.6882 - accuracy: 0.5413 - precision: 0.4900 - recall: 0.1516 - fbeta_score: 0.3195\n","\n","Epoch 2/5\n","\n","2656/2656 [==============================] - 1443s 543ms/step - loss: 0.6868 - accuracy: 0.5451 - precision: 0.5035 - recall: 0.1632 - fbeta_score: 0.3356\n","\n","Epoch 3/5\n","\n","2656/2656 [==============================] - 1525s 574ms/step - loss: 0.6837 - accuracy: 0.5556 - precision: 0.5391 - recall: 0.1837 - fbeta_score: 0.3687\n","\n","Epoch 4/5\n","\n","2656/2656 [==============================] - 1500s 565ms/step - loss: 0.6793 - accuracy: 0.5654 - precision: 0.5579 - recall: 0.2279 - fbeta_score: 0.4159\n","\n","Epoch 5/5\n","\n","2656/2656 [==============================] - 1464s 551ms/step - loss: 0.6749 - accuracy: 0.5815 - precision: 0.5755 - recall: 0.3232 - fbeta_score: 0.4857\n","\n","2h 3min 19s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"]}],"source":["%%timeit -n1 -r1\n","\n","history = model.fit_generator(\n","    train_datagen.flow(\n","        training_samples, \n","        train_labels, \n","        batch_size = BATCH_SIZE\n","    ),\n","    steps_per_epoch = len(training_samples) // BATCH_SIZE,\n","    validation_data = (validation_samples, valid_labels),\n","    validation_steps = len(validation_samples) // BATCH_SIZE,\n","    epochs = EPOCHS,\n","    callbacks = [checkpointer], \n","    verbose = 1\n",")"]},{"cell_type":"code","execution_count":null,"id":"6007dfac","metadata":{},"outputs":[],"source":["# Freeing Memory with Python's Garbase Collector\n","# del training_samples\n","# del validation_samples\n","# del train_labels\n","# del valid_labels\n","# gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Samples in Testing Set: 20%\n","test_labels = labelB[89696 : ][ : , np.newaxis]\n","test_samples = image_to_array(images_list[89696 : ], shape = IMAGE_SHAPE)\n","\n","prediction = model.predict(test_samples)"]},{"cell_type":"code","execution_count":null,"id":"7f9d51e2","metadata":{},"outputs":[],"source":["# Evaluation of Trained Model\n","threshold = 0.5\n","beta = 0.5\n","\n","accuracy = K.eval(binary_accuracy(K.variable(value=test_labels), K.variable(value=prediction)))\n","precision = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n","recall = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n","f1_score = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n","\n","print (f\"Accuracy: {accuracy} \\nRecall: {recall} \\nPrecision: {precision} \\nF1-Score: {f1_score}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}
