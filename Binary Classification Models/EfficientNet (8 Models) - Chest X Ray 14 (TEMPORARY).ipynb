{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69aebf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:02.758684Z",
     "iopub.status.busy": "2022-12-08T19:47:02.758218Z",
     "iopub.status.idle": "2022-12-08T19:47:09.366372Z",
     "shell.execute_reply": "2022-12-08T19:47:09.365390Z",
     "shell.execute_reply.started": "2022-12-08T19:47:02.758580Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.preprocessing import image                  \n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086bb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "class MultiLabelCrossEntropy:\n",
    "    \"\"\"\n",
    "    Weight Cross Entropy Loss.\n",
    "    \n",
    "    For each class we will found two weights corresponding to the positive and negative frequency of our sample data.\n",
    "    These weights will manage the way we update our network. And this has for objectives to manage the unbalanced class issue.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, labels : DataFrame, epsilon = 1e-7):\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Get the size of the data\n",
    "        self.N = labels.shape[0]\n",
    "        \n",
    "        # Get the frequency occurence for each class\n",
    "        self.freq_pos = np.sum(labels == 1, axis=0) / self.N\n",
    "        self.freq_neg = np.sum(labels == 0, axis=0) / self.N\n",
    "        \n",
    "        # Set the loss weights for each labels \n",
    "        self.pos_weights = self.freq_neg\n",
    "        self.neg_weights = self.freq_pos\n",
    "        \n",
    "    def contribution(self):\n",
    "        \"\"\"\n",
    "        Get the weights' contribution for each labels.\n",
    "        \n",
    "        Returns :\n",
    "            - double : Positive contribution\n",
    "            - double : Negative contribution\n",
    "        \"\"\"\n",
    "        return self.freq_pos * self.pos_weights, self.freq_neg * self.neg_weights\n",
    "        \n",
    "        \n",
    "    def loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Return weighted loss value. \n",
    "        \"\"\"\n",
    "        # Initialize loss to zero\n",
    "        loss = 0.0\n",
    "        \n",
    "        for i in range(len(self.pos_weights)):\n",
    "            loss += (\n",
    "                -1 * K.mean(self.pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + self.epsilon))\n",
    "                    ) + (\n",
    "                -1 * K.mean(self.neg_weights[i] * (1 - y_true[:,i]) * K.log(1 - y_pred[:,i] + self.epsilon))\n",
    "                    )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052c57ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:09.370618Z",
     "iopub.status.busy": "2022-12-08T19:47:09.369522Z",
     "iopub.status.idle": "2022-12-08T19:47:09.384326Z",
     "shell.execute_reply": "2022-12-08T19:47:09.383312Z",
     "shell.execute_reply.started": "2022-12-08T19:47:09.370576Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score\n",
    "\n",
    "def calculate_cm(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "def calculate_recall(tp, fp, fn, tn):\n",
    "    return (tp)/(tp + fn)\n",
    "\n",
    "def calculate_fallout(tp, fp, fn, tn):\n",
    "    return (fp)/(fp + tn)\n",
    "\n",
    "def calculate_fpr_tpr(y_true, y_pred):\n",
    "    tp, fp, fn, tn = calculate_cm(y_true, y_pred)\n",
    "    tpr = calculate_recall(tp, fp, fn, tn)\n",
    "    fpr = calculate_fallout(tp, fp, fn, tn)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784b0f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:09.386291Z",
     "iopub.status.busy": "2022-12-08T19:47:09.385669Z",
     "iopub.status.idle": "2022-12-08T19:47:09.412270Z",
     "shell.execute_reply": "2022-12-08T19:47:09.411179Z",
     "shell.execute_reply.started": "2022-12-08T19:47:09.386251Z"
    }
   },
   "outputs": [],
   "source": [
    "log = CSVLogger('saved_models/log_pretrained_CNN.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/pretrainedVGG.best.from_scratch.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717bd67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:09.417335Z",
     "iopub.status.busy": "2022-12-08T19:47:09.416610Z",
     "iopub.status.idle": "2022-12-08T19:47:09.694202Z",
     "shell.execute_reply": "2022-12-08T19:47:09.693095Z",
     "shell.execute_reply.started": "2022-12-08T19:47:09.417305Z"
    }
   },
   "outputs": [],
   "source": [
    "diseases = [\n",
    "    'Cardiomegaly','Emphysema','Effusion',\n",
    "    'Hernia','Nodule','Pneumothorax',\n",
    "    'Atelectasis','Pleural_Thickening',\n",
    "    'Mass','Edema','Consolidation',\n",
    "    'Infiltration','Fibrosis','Pneumonia'\n",
    "]\n",
    "\n",
    "dataset_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\n",
    "# dataset_df = pd.read_csv('./dataset_information/Data_Entry_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1968c71f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:09.696263Z",
     "iopub.status.busy": "2022-12-08T19:47:09.695686Z",
     "iopub.status.idle": "2022-12-08T19:47:10.307116Z",
     "shell.execute_reply": "2022-12-08T19:47:10.306116Z",
     "shell.execute_reply.started": "2022-12-08T19:47:09.696226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying One Hot Encoding to Labels\n",
    "for disease in diseases:\n",
    "    dataset_df[disease] = dataset_df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7a637d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:10.308977Z",
     "iopub.status.busy": "2022-12-08T19:47:10.308605Z",
     "iopub.status.idle": "2022-12-08T19:47:12.104011Z",
     "shell.execute_reply": "2022-12-08T19:47:12.102932Z",
     "shell.execute_reply.started": "2022-12-08T19:47:10.308938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Found: 112120\n"
     ]
    }
   ],
   "source": [
    "image_labels = dataset_df[diseases].to_numpy()\n",
    "image_paths = {\n",
    "    os.path.basename(x): x for x in glob(os.path.join('..', 'input', 'data', 'images*', 'images', '*.png'))\n",
    "#     os.path.basename(x): x for x in glob(os.path.join('.', 'images', '*.png'))\n",
    "}\n",
    "\n",
    "print(f\"Samples Found: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad451fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:12.107119Z",
     "iopub.status.busy": "2022-12-08T19:47:12.105350Z",
     "iopub.status.idle": "2022-12-08T19:47:12.148510Z",
     "shell.execute_reply": "2022-12-08T19:47:12.147521Z",
     "shell.execute_reply.started": "2022-12-08T19:47:12.107077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing path to each image against image name in the dataframe\n",
    "dataset_df['Image Path'] = dataset_df['Image Index'].map(image_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adad57c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:12.150709Z",
     "iopub.status.busy": "2022-12-08T19:47:12.150334Z",
     "iopub.status.idle": "2022-12-08T19:47:12.190766Z",
     "shell.execute_reply": "2022-12-08T19:47:12.189776Z",
     "shell.execute_reply.started": "2022-12-08T19:47:12.150673Z"
    }
   },
   "outputs": [],
   "source": [
    "images_list = dataset_df['Image Path'].tolist()\n",
    "\n",
    "labelB = (dataset_df[diseases].sum(axis = 1) > 0).tolist()\n",
    "labelB = np.array(labelB, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055e78fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:12.192898Z",
     "iopub.status.busy": "2022-12-08T19:47:12.192491Z",
     "iopub.status.idle": "2022-12-08T19:47:12.198660Z",
     "shell.execute_reply": "2022-12-08T19:47:12.197539Z",
     "shell.execute_reply.started": "2022-12-08T19:47:12.192838Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_image_to_tensor(path, shape):\n",
    "    # Loads RGB image to PIL format\n",
    "    img = image.load_img(path, target_size = shape)\n",
    "    \n",
    "    # Convert PIL image to 3D tensor of specific shape\n",
    "    # and normalizes it by dividing each pixel by 255\n",
    "    normalized_image_tensor = image.img_to_array(img) / 255\n",
    "    \n",
    "    # Convert 3D tensor to 4D tensor with specific shape \n",
    "    # (1, shape, 3) and return it\n",
    "    return np.expand_dims(normalized_image_tensor, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8595403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:12.203777Z",
     "iopub.status.busy": "2022-12-08T19:47:12.203350Z",
     "iopub.status.idle": "2022-12-08T19:47:12.211144Z",
     "shell.execute_reply": "2022-12-08T19:47:12.210096Z",
     "shell.execute_reply.started": "2022-12-08T19:47:12.203739Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_to_array(paths, shape):\n",
    "    images_arrays = [read_image_to_tensor(path, shape) for path in tqdm(paths, desc = \"Progress\", ncols = 100)]\n",
    "    return np.vstack(images_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c3675c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:12.212597Z",
     "iopub.status.busy": "2022-12-08T19:47:12.212328Z",
     "iopub.status.idle": "2022-12-08T19:47:12.221015Z",
     "shell.execute_reply": "2022-12-08T19:47:12.220051Z",
     "shell.execute_reply.started": "2022-12-08T19:47:12.212572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining some hyper-parameters\n",
    "IMAGE_SHAPE = (70, 70)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f2b039e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T19:47:12.223067Z",
     "iopub.status.busy": "2022-12-08T19:47:12.222712Z",
     "iopub.status.idle": "2022-12-08T20:20:56.181332Z",
     "shell.execute_reply": "2022-12-08T20:20:56.180342Z",
     "shell.execute_reply.started": "2022-12-08T19:47:12.223035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|███████████████████████████████████████████████| 78484/78484 [29:27<00:00, 44.41it/s]\n",
      "Progress: 100%|███████████████████████████████████████████████| 11212/11212 [04:11<00:00, 44.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Samples in Training Set: 70%\n",
    "# Samples in Validation Set: 10%\n",
    "\n",
    "# Storing labels of samples for each set\n",
    "train_labels = labelB[ : 78484][ : , np.newaxis]\n",
    "valid_labels = labelB[78484 : 89696][ : , np.newaxis]\n",
    "\n",
    "# Storing arrays of samples for each set\n",
    "training_samples = image_to_array(images_list[ : 78484], shape = IMAGE_SHAPE)\n",
    "validation_samples = image_to_array(images_list[78484 : 89696], shape = IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f80a6fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T20:20:56.183307Z",
     "iopub.status.busy": "2022-12-08T20:20:56.182835Z",
     "iopub.status.idle": "2022-12-08T20:21:04.530725Z",
     "shell.execute_reply": "2022-12-08T20:21:04.529755Z",
     "shell.execute_reply.started": "2022-12-08T20:20:56.183270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 20:20:56.347971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:56.445161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:56.445965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:56.447483: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-08 20:20:56.447817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:56.448518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:56.449173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:58.538212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:58.539054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:58.539722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 20:20:58.541190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "31793152/31790344 [==============================] - 3s 0us/step\n",
      "31801344/31790344 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Creating a model with EfficientNet as base.\n",
    "e_net = EfficientNetB2(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = training_samples.shape[1 : ]\n",
    ")\n",
    "\n",
    "custom_classifier = Sequential()\n",
    "custom_classifier.add(GlobalAveragePooling2D(input_shape = e_net.output_shape[1 : ]))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(256, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(512, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(256, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(50, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model = Model(inputs = e_net.input, outputs = custom_classifier(e_net.output))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8057ef37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T20:21:04.532713Z",
     "iopub.status.busy": "2022-12-08T20:21:04.532365Z",
     "iopub.status.idle": "2022-12-08T20:21:04.540223Z",
     "shell.execute_reply": "2022-12-08T20:21:04.537799Z",
     "shell.execute_reply.started": "2022-12-08T20:21:04.532675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining 2 optimizers to test the model with.\n",
    "\n",
    "SGD_optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate = 1e-4, \n",
    "    decay = 1e-6, \n",
    "    momentum = 0.9, \n",
    "    nesterov = True\n",
    ")\n",
    "adam_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.001,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ecfec53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T20:21:04.542329Z",
     "iopub.status.busy": "2022-12-08T20:21:04.541979Z",
     "iopub.status.idle": "2022-12-08T20:21:04.573236Z",
     "shell.execute_reply": "2022-12-08T20:21:04.572339Z",
     "shell.execute_reply.started": "2022-12-08T20:21:04.542295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining object for augmentation \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center = False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization = False,  # divide each input by its std\n",
    "    zca_whitening = False,  # apply ZCA whitening\n",
    "    rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True,  # randomly flip images\n",
    "    vertical_flip = False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "318ad721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T20:21:04.574874Z",
     "iopub.status.busy": "2022-12-08T20:21:04.574432Z",
     "iopub.status.idle": "2022-12-08T20:21:04.611271Z",
     "shell.execute_reply": "2022-12-08T20:21:04.610369Z",
     "shell.execute_reply.started": "2022-12-08T20:21:04.574817Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compiling model with loss function, optimizer and metrics\n",
    "\n",
    "model.compile(\n",
    "    optimizer = SGD_optimizer,\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.FalseNegatives(),\n",
    "        tf.keras.metrics.TrueNegatives(),\n",
    "        tf.keras.metrics.FalsePositives(),\n",
    "        tf.keras.metrics.TrueNegatives(),\n",
    "        precision_threshold(threshold = 0.5), \n",
    "        recall_threshold(threshold = 0.5), \n",
    "        fbeta_score_threshold(beta=0.5, threshold = 0.5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fa7f2e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T20:21:04.613041Z",
     "iopub.status.busy": "2022-12-08T20:21:04.612619Z",
     "iopub.status.idle": "2022-12-08T21:05:31.750505Z",
     "shell.execute_reply": "2022-12-08T21:05:31.749444Z",
     "shell.execute_reply.started": "2022-12-08T20:21:04.613006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-12-08 20:21:04.768748: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 20:21:17.743720: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452/2452 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5282 - false_negatives: 25158.0000 - true_negatives: 31242.0000 - false_positives: 11856.0000 - true_negatives_1: 31242.0000 - precision: 0.4629 - recall: 0.2880 - fbeta_score: 0.3859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 20:25:40.969926: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 659265600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452/2452 [==============================] - 289s 110ms/step - loss: 0.6949 - accuracy: 0.5282 - false_negatives: 25158.0000 - true_negatives: 31242.0000 - false_positives: 11856.0000 - true_negatives_1: 31242.0000 - precision: 0.4629 - recall: 0.2880 - fbeta_score: 0.3859 - val_loss: 0.7033 - val_accuracy: 0.4760 - val_false_negatives: 5836.0000 - val_true_negatives: 5282.0000 - val_false_positives: 39.0000 - val_true_negatives_1: 5282.0000 - val_precision: 0.1456 - val_recall: 0.0101 - val_fbeta_score: 0.0381\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70331, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "2452/2452 [==============================] - 258s 105ms/step - loss: 0.6878 - accuracy: 0.5436 - false_negatives: 28311.0000 - true_negatives: 35596.0000 - false_positives: 7496.0000 - true_negatives_1: 35596.0000 - precision: 0.4898 - recall: 0.1997 - fbeta_score: 0.3619\n",
      "Epoch 3/10\n",
      "2452/2452 [==============================] - 257s 105ms/step - loss: 0.6831 - accuracy: 0.5550 - false_negatives: 28210.0000 - true_negatives: 36396.0000 - false_positives: 6699.0000 - true_negatives_1: 36396.0000 - precision: 0.5158 - recall: 0.2029 - fbeta_score: 0.3776\n",
      "Epoch 4/10\n",
      "2452/2452 [==============================] - 255s 104ms/step - loss: 0.6784 - accuracy: 0.5638 - false_negatives: 26709.0000 - true_negatives: 35585.0000 - false_positives: 7511.0000 - true_negatives_1: 35585.0000 - precision: 0.5359 - recall: 0.2452 - fbeta_score: 0.4183\n",
      "Epoch 5/10\n",
      "2452/2452 [==============================] - 255s 104ms/step - loss: 0.6727 - accuracy: 0.5813 - false_negatives: 23087.0000 - true_negatives: 33333.0000 - false_positives: 9761.0000 - true_negatives_1: 33333.0000 - precision: 0.5583 - recall: 0.3490 - fbeta_score: 0.4884\n",
      "Epoch 6/10\n",
      "2452/2452 [==============================] - 255s 104ms/step - loss: 0.6659 - accuracy: 0.5970 - false_negatives: 20408.0000 - true_negatives: 31886.0000 - false_positives: 11208.0000 - true_negatives_1: 31886.0000 - precision: 0.5725 - recall: 0.4261 - fbeta_score: 0.5277\n",
      "Epoch 7/10\n",
      "2452/2452 [==============================] - 254s 104ms/step - loss: 0.6599 - accuracy: 0.6104 - false_negatives: 18325.0000 - true_negatives: 30860.0000 - false_positives: 12236.0000 - true_negatives_1: 30860.0000 - precision: 0.5834 - recall: 0.4853 - fbeta_score: 0.5544\n",
      "Epoch 8/10\n",
      "2452/2452 [==============================] - 259s 106ms/step - loss: 0.6539 - accuracy: 0.6204 - false_negatives: 17366.0000 - true_negatives: 30679.0000 - false_positives: 12413.0000 - true_negatives_1: 30679.0000 - precision: 0.5931 - recall: 0.5132 - fbeta_score: 0.5690\n",
      "Epoch 9/10\n",
      "2452/2452 [==============================] - 255s 104ms/step - loss: 0.6509 - accuracy: 0.6270 - false_negatives: 16580.0000 - true_negatives: 30414.0000 - false_positives: 12686.0000 - true_negatives_1: 30414.0000 - precision: 0.5980 - recall: 0.5349 - fbeta_score: 0.5786\n",
      "Epoch 10/10\n",
      "2452/2452 [==============================] - 255s 104ms/step - loss: 0.6458 - accuracy: 0.6355 - false_negatives: 16245.0000 - true_negatives: 30744.0000 - false_positives: 12348.0000 - true_negatives_1: 30744.0000 - precision: 0.6087 - recall: 0.5446 - fbeta_score: 0.5892\n",
      "44min 27s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(\n",
    "        training_samples, \n",
    "        train_labels, \n",
    "        batch_size = BATCH_SIZE\n",
    "    ),\n",
    "    steps_per_epoch = len(training_samples) // BATCH_SIZE,\n",
    "    validation_data = (validation_samples, valid_labels),\n",
    "    validation_steps = len(validation_samples) // BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = [checkpointer], \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c675c07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T21:05:31.753292Z",
     "iopub.status.busy": "2022-12-08T21:05:31.752652Z",
     "iopub.status.idle": "2022-12-08T21:05:32.037994Z",
     "shell.execute_reply": "2022-12-08T21:05:32.036825Z",
     "shell.execute_reply.started": "2022-12-08T21:05:31.753255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeing Memory with Python's Garbase Collector\n",
    "del training_samples\n",
    "del validation_samples\n",
    "del train_labels\n",
    "del valid_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b397830a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T21:05:32.041347Z",
     "iopub.status.busy": "2022-12-08T21:05:32.039714Z",
     "iopub.status.idle": "2022-12-08T21:14:57.842909Z",
     "shell.execute_reply": "2022-12-08T21:14:57.841882Z",
     "shell.execute_reply.started": "2022-12-08T21:05:32.041306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|███████████████████████████████████████████████| 22424/22424 [09:11<00:00, 40.68it/s]\n",
      "2022-12-08 21:14:43.933958: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1318531200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Samples in Testing Set: 20%\n",
    "test_labels = labelB[89696 : ][ : , np.newaxis]\n",
    "test_samples = image_to_array(images_list[89696 : ], shape = IMAGE_SHAPE)\n",
    "\n",
    "prediction = model.predict(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8df77340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T21:14:57.845566Z",
     "iopub.status.busy": "2022-12-08T21:14:57.845167Z",
     "iopub.status.idle": "2022-12-08T21:14:57.921146Z",
     "shell.execute_reply": "2022-12-08T21:14:57.920035Z",
     "shell.execute_reply.started": "2022-12-08T21:14:57.845530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5903941988945007 \n",
      "Recall: 0.8306812644004822 \n",
      "Specificity: 0.37899237153156173\n",
      "Precision: 0.5406176447868347 \n",
      "F1-Score: 0.5812076926231384\n",
      "\n",
      "True Positives: 8718 \n",
      "False Positives: 7408 \n",
      "False Negatives: 1777 \n",
      "True Negatives: 4521\n",
      "\n",
      "False Positve Rate: 62.10076284684383 % \n",
      "True Positive Rate: 83.06812767984755 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Trained Model\n",
    "testing_predictions = []\n",
    "for val in prediction:\n",
    "    if val[0] < 0.5:\n",
    "        testing_predictions.append([0])\n",
    "    else:\n",
    "        testing_predictions.append([1])\n",
    "\n",
    "testing_predictions = np.array(testing_predictions)\n",
    "\n",
    "TP, FP, FN, TN = calculate_cm(test_labels, testing_predictions)\n",
    "FPR, TPR = calculate_fpr_tpr(test_labels, testing_predictions)\n",
    "\n",
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "accuracy = K.eval(binary_accuracy(K.variable(value=test_labels), K.variable(value=prediction)))\n",
    "precision = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "recall = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "f1_score = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "\n",
    "print (f\"Accuracy: {accuracy} \\nRecall: {recall} \\nSpecificity: {TN / (TN + FP)}\\nPrecision: {precision} \\nF1-Score: {f1_score}\\n\")\n",
    "print (f\"True Positives: {TP} \\nFalse Positives: {FP} \\nFalse Negatives: {FN} \\nTrue Negatives: {TN}\\n\")\n",
    "print (f\"False Positve Rate: {FPR * 100} % \\nTrue Positive Rate: {TPR * 100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
