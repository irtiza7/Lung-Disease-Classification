{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3fa4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image                  \n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "from tensorflow.keras.applications import EfficientNetB6\n",
    "from tensorflow.keras.applications import EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a75c69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = CSVLogger('saved_models/log_pretrained_CNN.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/pretrainedVGG.best.from_scratch.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2c15a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = [\n",
    "    'Cardiomegaly','Emphysema','Effusion',\n",
    "    'Hernia','Nodule','Pneumothorax',\n",
    "    'Atelectasis','Pleural_Thickening',\n",
    "    'Mass','Edema','Consolidation',\n",
    "    'Infiltration','Fibrosis','Pneumonia'\n",
    "]\n",
    "\n",
    "dataset_df = pd.read_csv('./dataset_information/Data_Entry_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d2239a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying One Hot Encoding to Labels\n",
    "for disease in diseases:\n",
    "    dataset_df[disease] = dataset_df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "743b7dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Found: 112120\n"
     ]
    }
   ],
   "source": [
    "image_labels = dataset_df[diseases].to_numpy()\n",
    "image_paths = {\n",
    "    os.path.basename(x): x for x in glob(os.path.join('.', 'images', '*.png'))\n",
    "}\n",
    "\n",
    "print(f\"Samples Found: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a8c9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing path to each image against image name in the dataframe\n",
    "dataset_df['Image Path'] = dataset_df['Image Index'].map(image_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ee4a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = dataset_df['Image Path'].tolist()\n",
    "\n",
    "labelB = (dataset_df[diseases].sum(axis = 1) > 0).tolist()\n",
    "labelB = np.array(labelB, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af83e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_to_tensor(path, shape):\n",
    "    # Loads RGB image to PIL format\n",
    "    img = image.load_img(path, target_size = shape)\n",
    "    \n",
    "    # Convert PIL image to 3D tensor of specific shape\n",
    "    # and normalizes it by dividing each pixel by 255\n",
    "    normalized_image_tensor = image.img_to_array(img) / 255\n",
    "    \n",
    "    # Convert 3D tensor to 4D tensor with specific shape \n",
    "    # (1, shape, 3) and return it\n",
    "    return np.expand_dims(normalized_image_tensor, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cefbf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(paths, shape):\n",
    "    images_arrays = [read_image_to_tensor(path, shape) for path in tqdm(paths, desc = \"Progress\", ncols = 100)]\n",
    "    return np.vstack(images_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f3b5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caa167b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████████████████████████| 7500/7500 [01:43<00:00, 72.34it/s]\n",
      "Progress: 100%|█████████████████████████████████████████████████| 1000/1000 [00:13<00:00, 75.74it/s]\n",
      "Progress: 100%|█████████████████████████████████████████████████| 3500/3500 [00:47<00:00, 73.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Samples in Training Set: 70%\n",
    "# Samples in Validation Set: 8%\n",
    "# Samples in Testing Set: 22%\n",
    "\n",
    "# Storing labels of samples for each set\n",
    "train_labels = labelB[ : 85000][ : , np.newaxis]\n",
    "valid_labels = labelB[85000 : 95000][ : , np.newaxis]\n",
    "test_labels = labelB[95000 : ][ : , np.newaxis]\n",
    "\n",
    "# Storing arrays of samples for each set\n",
    "training_samples = image_to_array(images_list[ : 85000], shape = IMAGE_SHAPE)\n",
    "validation_samples = image_to_array(images_list[85000 : 95000], shape = IMAGE_SHAPE)\n",
    "test_samples = image_to_array(images_list[95000 : ], shape = IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a93edfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
      "27025408/27018416 [==============================] - 29s 1us/step\n",
      "27033600/27018416 [==============================] - 29s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Creating a model with EfficientNet B0 as base.\n",
    "efficient_net_b0 = EfficientNetB0(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = training_samples.shape[1 : ]\n",
    ")\n",
    "\n",
    "custom_classifier = Sequential()\n",
    "custom_classifier.add(GlobalAveragePooling2D(input_shape = efficient_net_b0.output_shape[1 : ]))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(256, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(512, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(256, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(50, activation = 'relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "custom_classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model = Model(inputs = efficient_net_b0.input, outputs = custom_classifier(efficient_net_b0.output))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9ea5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 2 optimizers to test the model with.\n",
    "\n",
    "SGD_optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate = 1e-4, \n",
    "    decay = 1e-6, \n",
    "    momentum = 0.9, \n",
    "    nesterov = True\n",
    ")\n",
    "adam_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.001,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bc98a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining object for augmentation \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center = False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization = False,  # divide each input by its std\n",
    "    zca_whitening = False,  # apply ZCA whitening\n",
    "    rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True,  # randomly flip images\n",
    "    vertical_flip = False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef942e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some hyper-parameters\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2952d9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compiling model with loss function, optimizer and metrics\n",
    "\n",
    "model.compile(\n",
    "    optimizer = SGD_optimizer,\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        precision_threshold(threshold = 0.5), \n",
    "        recall_threshold(threshold = 0.5), \n",
    "        fbeta_score_threshold(beta=0.5, threshold = 0.5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "525121b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "234/234 [==============================] - 44s 137ms/step - loss: 0.7006 - accuracy: 0.5281 - precision: 0.4490 - recall: 0.3352 - fbeta_score: 0.4089 - val_loss: 0.6917 - val_accuracy: 0.5150 - val_precision: 0.4137 - val_recall: 0.3479 - val_fbeta_score: 0.3771\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.67779\n",
      "Epoch 2/5\n",
      "234/234 [==============================] - 29s 126ms/step - loss: 0.6985 - accuracy: 0.5359 - precision: 0.4399 - recall: 0.2417 - fbeta_score: 0.3664 - val_loss: 0.7002 - val_accuracy: 0.4410 - val_precision: 0.4004 - val_recall: 0.7430 - val_fbeta_score: 0.4358\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67779\n",
      "Epoch 3/5\n",
      "234/234 [==============================] - 30s 126ms/step - loss: 0.6969 - accuracy: 0.5371 - precision: 0.4360 - recall: 0.2393 - fbeta_score: 0.3635 - val_loss: 0.6873 - val_accuracy: 0.5680 - val_precision: 0.3602 - val_recall: 0.1104 - val_fbeta_score: 0.2228\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67779\n",
      "Epoch 4/5\n",
      "234/234 [==============================] - 29s 125ms/step - loss: 0.6998 - accuracy: 0.5398 - precision: 0.4440 - recall: 0.2188 - fbeta_score: 0.3524 - val_loss: 0.6910 - val_accuracy: 0.5770 - val_precision: 0.4426 - val_recall: 0.1600 - val_fbeta_score: 0.3078\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67779\n",
      "Epoch 5/5\n",
      "234/234 [==============================] - 30s 127ms/step - loss: 0.6992 - accuracy: 0.5445 - precision: 0.4591 - recall: 0.2053 - fbeta_score: 0.3505 - val_loss: 0.6918 - val_accuracy: 0.5100 - val_precision: 0.3734 - val_recall: 0.2893 - val_fbeta_score: 0.3395\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67779\n",
      "2min 42s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(\n",
    "        training_samples, \n",
    "        train_labels, \n",
    "        batch_size = BATCH_SIZE\n",
    "    ),\n",
    "    steps_per_epoch = len(training_samples) // BATCH_SIZE,\n",
    "    validation_data = (validation_samples, valid_labels),\n",
    "    validation_steps = len(validation_samples) // BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = [checkpointer, log], \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "160295a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1c4bad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "accuracy = K.eval(binary_accuracy(K.variable(value=test_labels), K.variable(value=prediction)))\n",
    "precision = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "recall = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))\n",
    "f1_score = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa301935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5217142701148987 \n",
      "Precision: 0.3809082508087158 \n",
      "Recall: 0.29004940390586853 \n",
      "F1-Score: 0.3584509789943695\n"
     ]
    }
   ],
   "source": [
    "print (f\"Accuracy: {accuracy} \\nPrecision: {precision} \\nRecall: {recall} \\nF1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac8dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
