{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94ea0dc",
   "metadata": {},
   "source": [
    "#### Importing Libraries and built-in Models from Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937500a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:17:17.560168Z",
     "iopub.status.busy": "2022-12-13T00:17:17.559846Z",
     "iopub.status.idle": "2022-12-13T00:17:25.150281Z",
     "shell.execute_reply": "2022-12-13T00:17:25.149337Z",
     "shell.execute_reply.started": "2022-12-13T00:17:17.560092Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "from tensorflow.keras.applications import EfficientNetB6\n",
    "from tensorflow.keras.applications import EfficientNetB7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6086b0",
   "metadata": {},
   "source": [
    "#### Defining helping functions.\n",
    "* calculate_cm returns true_positives, false_positives, false_negatives and true_negatives, for Binary Classification Problem.\n",
    "* calculate_recall returns value of Recall evaluation measure, for Binary Classification Problem.\n",
    "* calculate_fallout returns false_positive_rate, for Binary Classification Problem.\n",
    "* calculate_fpr_tpr returns false_positve_rate and true_positive_rate, for Binary Classification Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd1907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:17:25.165641Z",
     "iopub.status.busy": "2022-12-13T00:17:25.164854Z",
     "iopub.status.idle": "2022-12-13T00:17:25.183000Z",
     "shell.execute_reply": "2022-12-13T00:17:25.182025Z",
     "shell.execute_reply.started": "2022-12-13T00:17:25.165605Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_cm(y_true, y_pred):\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "def calculate_recall(tp, fp, fn, tn):\n",
    "    return (tp)/(tp + fn)\n",
    "\n",
    "def calculate_fallout(tp, fp, fn, tn):\n",
    "    return (fp)/(fp + tn)\n",
    "\n",
    "def calculate_fpr_tpr(y_true, y_pred):\n",
    "    tp, fp, fn, tn = calculate_cm(y_true, y_pred)\n",
    "    tpr = calculate_recall(tp, fp, fn, tn)\n",
    "    fpr = calculate_fallout(tp, fp, fn, tn)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c1e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:17:25.186332Z",
     "iopub.status.busy": "2022-12-13T00:17:25.185867Z",
     "iopub.status.idle": "2022-12-13T00:19:20.252152Z",
     "shell.execute_reply": "2022-12-13T00:19:20.251133Z",
     "shell.execute_reply.started": "2022-12-13T00:17:25.186299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112120/112120 [01:37<00:00, 1149.90it/s]\n"
     ]
    }
   ],
   "source": [
    "image_paths = {os.path.basename(x): x for x in glob(os.path.join('..', 'input', 'data', 'images*', 'images', '*.png'))}\n",
    "df = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")\n",
    "\n",
    "df = df.drop(\n",
    "    columns = [\n",
    "        \"Follow-up #\", \n",
    "        \"Patient ID\", \n",
    "        \"Patient Age\", \n",
    "        \"Patient Gender\", \n",
    "        \"OriginalImage[Width\",\n",
    "        \"Height]\",\n",
    "        \"OriginalImagePixelSpacing[x\",\n",
    "        \"y]\",\n",
    "        \"Unnamed: 11\",\n",
    "        \"View Position\"\n",
    "    ], \n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "df[\"Image Paths\"] = \" \"\n",
    "for row_index in tqdm(range(len(df))):\n",
    "    img_name = df.iloc[row_index][0]\n",
    "    path = image_paths[img_name]\n",
    "    df[\"Image Paths\"][row_index] = path\n",
    "\n",
    "unique_labels = set(itertools.chain.from_iterable(df[\"Finding Labels\"].apply(lambda x : x.split('|')).values)) \n",
    "one_hot_labels = pd.DataFrame(0.0, index = np.arange(len(df)), columns = unique_labels)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    labels = row[\"Finding Labels\"].split('|')\n",
    "    for label in labels:\n",
    "        one_hot_labels.iloc[index][label] = 1.0\n",
    "\n",
    "df = pd.concat([df, one_hot_labels], axis = 1)\n",
    "df = df.drop(columns = [\"Finding Labels\"], axis = 1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5931d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:19:20.254034Z",
     "iopub.status.busy": "2022-12-13T00:19:20.253633Z",
     "iopub.status.idle": "2022-12-13T00:19:20.314915Z",
     "shell.execute_reply": "2022-12-13T00:19:20.313715Z",
     "shell.execute_reply.started": "2022-12-13T00:19:20.253972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 80726\n",
      "Validation Samples: 8970\n",
      "Testing Samples: 22424\n"
     ]
    }
   ],
   "source": [
    "# df_train, df_test = train_test_split(dataset_info.sample(n = 60000), test_size = 0.20, random_state = 142)\n",
    "df_train, df_test = train_test_split(df, test_size = 0.20, random_state = 0)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.10, random_state = 0)\n",
    "\n",
    "print(f\"Training Samples: {len(df_train)}\\nValidation Samples: {len(df_val)}\\nTesting Samples: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = [\n",
    "    \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Effusion\", \"Emphysema\", \"Fibrosis\", \"Hernia\", \n",
    "    \"Infiltration\", \"Mass\", \"No Finding\", \"Nodule\", \"Pleural_Thickening\", \"Pneumonia\",\"Pneumothorax\"\n",
    "]\n",
    "IMAGE_SIZE = (224, 224,)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "BETA_FOR_BIASED_RECALL = 1.3\n",
    "BETA_FOR_BIASED_PRECISION = 0.7\n",
    "BETA_WITH_NO_BIAS = 1\n",
    "\n",
    "THRESHOLDS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "METRICS = [\n",
    "  tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "  tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "  tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "  tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "  tf.keras.metrics.BinaryAccuracy(name = 'binary_accuracy'),\n",
    "  tf.keras.metrics.Precision(name = 'precision', thresholds = 0.3),\n",
    "  tf.keras.metrics.Recall(name = 'recall', thresholds = 0.3),\n",
    "  tf.keras.metrics.AUC(name = 'auc', multi_label = True, num_labels = 15, thresholds = THRESHOLDS),\n",
    "  tf.keras.metrics.AUC(name = 'prc', curve = 'PR')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7733e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:19:20.325954Z",
     "iopub.status.busy": "2022-12-13T00:19:20.325522Z",
     "iopub.status.idle": "2022-12-13T00:19:20.334253Z",
     "shell.execute_reply": "2022-12-13T00:19:20.333194Z",
     "shell.execute_reply.started": "2022-12-13T00:19:20.325918Z"
    }
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(image_generator, dataframe):\n",
    "    df_gen = image_generator.flow_from_dataframe(\n",
    "        dataframe,\n",
    "        x_col = \"Image Paths\", \n",
    "        y_col = dataframe.columns[2:],\n",
    "        target_size = IMAGE_SIZE,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'raw',\n",
    "        shuffle = False,\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n",
    "    return df_gen\n",
    "\n",
    "def sharpen_image(image):\n",
    "    sharp_kernel = np.array(\n",
    "        [\n",
    "            [0, -1, 0], \n",
    "            [-1, 5, -1], \n",
    "            [0, -1, 0]\n",
    "        ])\n",
    "    output = cv2.filter2D(src = image, ddepth = -1, kernel = sharp_kernel)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    preprocessing_function = sharpen_image,\n",
    "    zca_whitening = False,\n",
    "    rotation_range = 20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True\n",
    ")\n",
    "val_data_generator = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    preprocessing_function = sharpen_image\n",
    ")\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    preprocessing_function = sharpen_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1765596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = flow_from_dataframe(image_generator = train_data_generator, dataframe = df_train)\n",
    "valid_gen = flow_from_dataframe(image_generator = val_data_generator, dataframe = df_val)\n",
    "test_gen = flow_from_dataframe(image_generator = test_data_generator, dataframe = df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99947b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:20:48.394372Z",
     "iopub.status.busy": "2022-12-13T00:20:48.393929Z",
     "iopub.status.idle": "2022-12-13T00:20:48.400620Z",
     "shell.execute_reply": "2022-12-13T00:20:48.399561Z",
     "shell.execute_reply.started": "2022-12-13T00:20:48.394335Z"
    }
   },
   "outputs": [],
   "source": [
    "SGD_optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate = 0.0001, \n",
    "    decay = 1e-6, \n",
    "    momentum = 0.9, \n",
    "    nesterov = True\n",
    ")\n",
    "adam_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.0001,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9075398",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0,\n",
    "    patience = 4,\n",
    "    verbose = 1,\n",
    "    mode = 'auto',\n",
    "    baseline = None,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8826b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:20:48.414043Z",
     "iopub.status.busy": "2022-12-13T00:20:48.413675Z",
     "iopub.status.idle": "2022-12-13T00:20:48.437638Z",
     "shell.execute_reply": "2022-12-13T00:20:48.436609Z",
     "shell.execute_reply.started": "2022-12-13T00:20:48.414006Z"
    }
   },
   "outputs": [],
   "source": [
    "channels = (3,)\n",
    "input_shape = IMAGE_SIZE + channels\n",
    "img_input = Input(shape = input_shape)\n",
    "\n",
    "MODEL_NAME = \"VGG16\"\n",
    "base_model = VGG16(\n",
    "    input_shape = input_shape,\n",
    "    include_top = False,\n",
    "    weights = \"imagenet\"\n",
    ")\n",
    "\n",
    "custom_classifier = Sequential()\n",
    "custom_classifier.add(GlobalAveragePooling2D(input_shape = base_model.output_shape[1:]))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "\n",
    "custom_classifier.add(Dense(256))\n",
    "custom_classifier.add(BatchNormalization())\n",
    "custom_classifier.add(Activation('relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "\n",
    "custom_classifier.add(Dense(50))\n",
    "custom_classifier.add(BatchNormalization())\n",
    "custom_classifier.add(Activation('relu'))\n",
    "custom_classifier.add(Dropout(0.2))\n",
    "\n",
    "custom_classifier.add(Dense(15, activation = \"sigmoid\"))\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = custom_classifier(base_model.output))\n",
    "# model.load_weights(\"/kaggle/working/inceptionv3_5_weights.h5\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = adam_optimizer,\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9397b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T00:20:48.439347Z",
     "iopub.status.busy": "2022-12-13T00:20:48.439039Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-12-13 00:20:48.966676: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 00:20:58.053228: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5045/5045 [==============================] - 2199s 433ms/step - loss: 0.2203 - tp: 30526.0000 - fp: 20710.0000 - tn: 1088369.0000 - fn: 71285.0000 - accuracy: 0.9240 - precision: 0.5958 - recall: 0.2998 - auc: 0.8285 - prc: 0.4141 - f1_score: 0.0453 - val_loss: 0.5581 - val_tp: 3948.0000 - val_fp: 2756.0000 - val_tn: 120412.0000 - val_fn: 7434.0000 - val_accuracy: 0.9243 - val_precision: 0.5889 - val_recall: 0.3469 - val_auc: 0.7816 - val_prc: 0.3921 - val_f1_score: 0.0457\n",
      "Epoch 2/15\n",
      "5045/5045 [==============================] - 2187s 433ms/step - loss: 0.2099 - tp: 31491.0000 - fp: 17255.0000 - tn: 1091824.0000 - fn: 70320.0000 - accuracy: 0.9277 - precision: 0.6460 - recall: 0.3093 - auc: 0.8473 - prc: 0.4570 - f1_score: 0.0455 - val_loss: 0.2077 - val_tp: 3924.0000 - val_fp: 2166.0000 - val_tn: 121002.0000 - val_fn: 7458.0000 - val_accuracy: 0.9285 - val_precision: 0.6443 - val_recall: 0.3448 - val_auc: 0.8552 - val_prc: 0.4738 - val_f1_score: 0.0480\n",
      "Epoch 3/15\n",
      "5045/5045 [==============================] - 2242s 444ms/step - loss: 0.2054 - tp: 31300.0000 - fp: 15112.0000 - tn: 1093967.0000 - fn: 70511.0000 - accuracy: 0.9293 - precision: 0.6744 - recall: 0.3074 - auc: 0.8562 - prc: 0.4762 - f1_score: 0.0467 - val_loss: 0.2048 - val_tp: 3408.0000 - val_fp: 1510.0000 - val_tn: 121658.0000 - val_fn: 7974.0000 - val_accuracy: 0.9295 - val_precision: 0.6930 - val_recall: 0.2994 - val_auc: 0.8603 - val_prc: 0.4831 - val_f1_score: 0.0467\n",
      "Epoch 4/15\n",
      "5045/5045 [==============================] - 2264s 449ms/step - loss: 0.2022 - tp: 31974.0000 - fp: 14506.0000 - tn: 1094573.0000 - fn: 69837.0000 - accuracy: 0.9303 - precision: 0.6879 - recall: 0.3141 - auc: 0.8625 - prc: 0.4890 - f1_score: 0.0482 - val_loss: 0.2060 - val_tp: 3679.0000 - val_fp: 1862.0000 - val_tn: 121306.0000 - val_fn: 7703.0000 - val_accuracy: 0.9289 - val_precision: 0.6640 - val_recall: 0.3232 - val_auc: 0.8574 - val_prc: 0.4757 - val_f1_score: 0.0474\n",
      "Epoch 5/15\n",
      "5045/5045 [==============================] - 2228s 442ms/step - loss: 0.2006 - tp: 32030.0000 - fp: 14260.0000 - tn: 1094819.0000 - fn: 69781.0000 - accuracy: 0.9306 - precision: 0.6919 - recall: 0.3146 - auc: 0.8664 - prc: 0.4955 - f1_score: 0.0493 - val_loss: 0.2002 - val_tp: 3698.0000 - val_fp: 1631.0000 - val_tn: 121537.0000 - val_fn: 7684.0000 - val_accuracy: 0.9308 - val_precision: 0.6939 - val_recall: 0.3249 - val_auc: 0.8692 - val_prc: 0.5068 - val_f1_score: 0.0544\n",
      "Epoch 6/15\n",
      "5045/5045 [==============================] - 2190s 434ms/step - loss: 0.1986 - tp: 32152.0000 - fp: 13833.0000 - tn: 1095246.0000 - fn: 69659.0000 - accuracy: 0.9311 - precision: 0.6992 - recall: 0.3158 - auc: 0.8709 - prc: 0.5028 - f1_score: 0.0494 - val_loss: 0.2160 - val_tp: 4280.0000 - val_fp: 2700.0000 - val_tn: 120468.0000 - val_fn: 7102.0000 - val_accuracy: 0.9272 - val_precision: 0.6132 - val_recall: 0.3760 - val_auc: 0.8553 - val_prc: 0.4870 - val_f1_score: 0.0484\n",
      "Epoch 7/15\n",
      "5045/5045 [==============================] - 2241s 444ms/step - loss: 0.1971 - tp: 32602.0000 - fp: 13972.0000 - tn: 1095107.0000 - fn: 69209.0000 - accuracy: 0.9313 - precision: 0.7000 - recall: 0.3202 - auc: 0.8741 - prc: 0.5077 - f1_score: 0.0515 - val_loss: 0.2001 - val_tp: 3967.0000 - val_fp: 1972.0000 - val_tn: 121196.0000 - val_fn: 7415.0000 - val_accuracy: 0.9302 - val_precision: 0.6680 - val_recall: 0.3485 - val_auc: 0.8719 - val_prc: 0.5026 - val_f1_score: 0.0501\n",
      "Epoch 8/15\n",
      "5045/5045 [==============================] - 2180s 432ms/step - loss: 0.1959 - tp: 32783.0000 - fp: 13893.0000 - tn: 1095186.0000 - fn: 69028.0000 - accuracy: 0.9315 - precision: 0.7024 - recall: 0.3220 - auc: 0.8767 - prc: 0.5112 - f1_score: 0.0544 - val_loss: 0.2019 - val_tp: 3253.0000 - val_fp: 1270.0000 - val_tn: 121898.0000 - val_fn: 8129.0000 - val_accuracy: 0.9301 - val_precision: 0.7192 - val_recall: 0.2858 - val_auc: 0.8674 - val_prc: 0.4955 - val_f1_score: 0.0467\n",
      "Epoch 9/15\n",
      "1393/5045 [=======>......................] - ETA: 24:07 - loss: 0.1951 - tp: 9188.0000 - fp: 3870.0000 - tn: 302220.0000 - fn: 19042.0000 - accuracy: 0.9315 - precision: 0.7036 - recall: 0.3255 - auc: 0.8791 - prc: 0.5172 - f1_score: 0.0562"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    epochs = EPOCHS,\n",
    "    generator = train_gen,\n",
    "    steps_per_epoch = train_gen.n / train_gen.batch_size,\n",
    "    validation_data = valid_gen,\n",
    "    validation_steps = valid_gen.n / valid_gen.batch_size,\n",
    "    shuffle = False,\n",
    "    verbose = 1,\n",
    "    callbacks = None\n",
    ")\n",
    "\n",
    "print(f\"\\nTime Taken: {(time.time() - start_time) / 3600 : .4f} Hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['loss'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_loss'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['binary_accuracy'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_binary_accuracy'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Binary Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['recall'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_recall'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['precision'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_precision'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['auc'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_auc'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7, figsize = (6,3))\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['prc'], 'g', label = 'Training')\n",
    "plt.plot([int(x) for x in range(1, EPOCHS + 1)], history.history['val_prc'], 'b', label = 'Validation')\n",
    "plt.title(f'{MODEL_NAME} Training & Validation PRC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('PRC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a223f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(f\"/kaggle/working/VGG16_{EPOCHS}_weights.h5\")\n",
    "evaluation = model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f91788",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluation[0]\n",
    "TP = evaluation[1]\n",
    "FP = evaluation[2]\n",
    "TN = evaluation[3]\n",
    "FN = evaluation[4]\n",
    "binary_accuracy = evaluation[5] * 100\n",
    "auc = evaluation[8] * 100\n",
    "auc_pr = evaluation[9] * 100\n",
    "\n",
    "specificity = (TN / (TN + FP)) * 100\n",
    "recall = (TP / (TP + FN)) * 100\n",
    "precision = (TP / (TP + FP)) * 100\n",
    "f1_score = (2 * recall * precision) / (recall + precision)\n",
    "\n",
    "print(f\"Testing Loss: \\t\\t{test_loss}\\n\")\n",
    "print(f\"True Positives: \\t{TP}\\nFalse Positives: \\t{FP}\\nTrue Negatives: \\t{TN}\\nFalse Negatives: \\t{FN}\\n\")\n",
    "print(f\"Binary Accuracy: \\t{binary_accuracy}\")\n",
    "print(f\"Average Recall: \\t{recall}\\nAverage Precision: \\t{precision}\\nF1-Score: \\t\\t{f1_score}\\nAverage Specificity: \\t{specificity}\\n\")\n",
    "print(f\"AUC: \\t\\t\\t{auc}\\nAUC-PR: \\t\\t{auc_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "predictions = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score\n",
    "    \n",
    "def print_results(beta, threshold, test_labels, prediction):\n",
    "    accuracy = K.eval(binary_accuracy(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    precision = K.eval(precision_threshold(threshold = threshold)(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    recall = K.eval(recall_threshold(threshold = threshold)(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    f1_score = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value = test_labels), K.variable(value = prediction)))\n",
    "    print(f\"BETA: {beta}, THRESHOLD: {threshold}\")\n",
    "    print (f\"Binary Accuracy: \\t{accuracy * 100} % \\nRecall: \\t\\t{recall * 100} % \\nPrecision: \\t\\t{precision * 100} % \\nF1-Score: \\t\\t{f1_score * 100} %\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b16d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for label in test_gen.labels:\n",
    "    test_labels.append(label)\n",
    "\n",
    "# # Results with F Score giving more weightage to Recall\n",
    "# for threshold in THRESHOLDS:\n",
    "#     print_results(beta = BETA_FOR_BIASED_RECALL, threshold = threshold, test_labels = test_labels, prediction = predictions)\n",
    "\n",
    "# # Results with F Score giving more weightage to Precision\n",
    "# for threshold in THRESHOLDS:\n",
    "#     print_results(beta = BETA_FOR_BIASED_PRECISION, threshold = threshold, test_labels = test_labels, prediction = predictions)\n",
    "\n",
    "# Results with F Score giving equal weightage to Recall and Precision\n",
    "for threshold in THRESHOLDS:\n",
    "    print_results(beta = BETA_WITH_NO_BIAS, threshold = threshold, test_labels = test_labels, prediction = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names,)\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    axes.set_ylabel('True label')\n",
    "    axes.set_xlabel('Predicted label')\n",
    "    axes.set_title(\"Confusion Matrix - \" + class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "y_test = test_gen.labels\n",
    "y_predicted = (predictions >= threshold).astype(int)\n",
    "confusion_matrix = multilabel_confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize=(22, 10))\n",
    "for axes, cfs_matrix, label in zip(ax.flatten(), confusion_matrix, CLASS_LABELS):\n",
    "    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06661a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "colors = cycle(['blue', 'red', 'green', 'black', 'purple', 'magenta', 'cyan', 'orange', 'teal', 'darkgreen'])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "lw = 2\n",
    "\n",
    "for i in range(len(CLASS_LABELS)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions[:, i])\n",
    "    roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "avg_auc = 0\n",
    "for auc_value in roc_auc.values():\n",
    "    avg_auc += auc_value\n",
    "print(f\"[{MODEL_NAME} with {EPOCHS} Epochs] - Average AUC: {avg_auc / 15}\")\n",
    "    \n",
    "for i, color in zip(range(len(CLASS_LABELS)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color = color, lw = 2, label = '{0} (AUC = {1:0.2f})'''.format(CLASS_LABELS[i], roc_auc[i]))\n",
    "\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC - {MODEL_NAME} with {EPOCHS} Epochs')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
