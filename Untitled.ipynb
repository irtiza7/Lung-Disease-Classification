{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3fa4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from keras.preprocessing import image                  \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2c15a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = [\n",
    "    'Cardiomegaly','Emphysema','Effusion',\n",
    "    'Hernia','Nodule','Pneumothorax',\n",
    "    'Atelectasis','Pleural_Thickening',\n",
    "    'Mass','Edema','Consolidation',\n",
    "    'Infiltration','Fibrosis','Pneumonia',\n",
    "    'No Finding'\n",
    "]\n",
    "\n",
    "dataset_df = pd.read_csv('./dataset_information/Data_Entry_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d2239a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying One Hot Encoding to Labels\n",
    "for disease in diseases:\n",
    "    dataset_df[disease] = dataset_df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "743b7dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Found: 112120\n"
     ]
    }
   ],
   "source": [
    "image_labels = dataset_df[diseases].to_numpy()\n",
    "image_paths = {\n",
    "    os.path.basename(x): x for x in glob(os.path.join('.', 'images', '*.png'))\n",
    "}\n",
    "\n",
    "print(f\"Samples Found: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a8c9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing path to each image name in the dataframe\n",
    "dataset_df['Image Path'] = dataset_df['Image Index'].map(image_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ee4a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = dataset_df['Image Path'].tolist()\n",
    "\n",
    "labelB = (dataset_df[diseases].sum(axis = 1) > 0).tolist()\n",
    "labelB = np.array(labelB, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af83e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_to_tensor(path, shape):\n",
    "    # Loads RGB image to PIL format\n",
    "    img = image.load_img(path, target_size = shape)\n",
    "    \n",
    "    # Convert PIL image to 3D tensor of specific shape\n",
    "    # and normalizes it by dividing each pixel by 255\n",
    "    normalized_image_tensor = image.img_to_array(img) / 255\n",
    "    \n",
    "    # Convert 3D tensor to 4D tensor with specific shape \n",
    "    # (1, shape, 3) and return it\n",
    "    return np.expand_dims(normalized_image_tensor, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cefbf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(paths, shape):\n",
    "    images_arrays = []\n",
    "    for path in tqdm(paths, desc = \"Progress\", ncols = 100):\n",
    "        images_arrays.append(read_image_to_tensor(path, shape))\n",
    "    return images_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f3b5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = labelB[ : 75000][ : , np.newaxis]\n",
    "valid_labels = labelB[75000 : 85000][ : , np.newaxis]\n",
    "test_labels = labelB[85000 : ][ : , np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "caa167b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   1%|‚ñç                                                | 714/75000 [00:09<16:53, 73.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m IMAGE_SHAPE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m training_samples \u001b[38;5;241m=\u001b[39m \u001b[43mimage_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m75000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mIMAGE_SHAPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m validation_samples \u001b[38;5;241m=\u001b[39m image_to_array(images_list[\u001b[38;5;241m75000\u001b[39m : \u001b[38;5;241m85000\u001b[39m], shape \u001b[38;5;241m=\u001b[39m IMAGE_SHAPE)\n\u001b[0;32m      5\u001b[0m test_samples \u001b[38;5;241m=\u001b[39m image_to_array(images_list[\u001b[38;5;241m85000\u001b[39m : ], shape \u001b[38;5;241m=\u001b[39m IMAGE_SHAPE)\n",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36mimage_to_array\u001b[1;34m(paths, shape)\u001b[0m\n\u001b[0;32m      2\u001b[0m images_arrays \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m tqdm(paths, desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress\u001b[39m\u001b[38;5;124m\"\u001b[39m, ncols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     images_arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_image_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images_arrays\n",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36mread_image_to_tensor\u001b[1;34m(path, shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_image_to_tensor\u001b[39m(path, shape):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Loads RGB image to PIL format\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert PIL image to 3D tensor of specific shape\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# and normalizes it by dividing each pixel by 255\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     normalized_image_tensor \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:313\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.utils.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    278\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.load_img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m              interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    281\u001b[0m   \u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m  Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:125\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_mode must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\PIL\\Image.py:901\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    858\u001b[0m ):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\PIL\\ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         )\n\u001b[0;32m    256\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 257\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (64, 64)\n",
    "\n",
    "training_samples = image_to_array(images_list[ : 75000], shape = IMAGE_SHAPE)\n",
    "validation_samples = image_to_array(images_list[75000 : 85000], shape = IMAGE_SHAPE)\n",
    "test_samples = image_to_array(images_list[85000 : ], shape = IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93edfad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
